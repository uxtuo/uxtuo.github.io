<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Msys2]]></title>
      <url>/2018/02/08/Msys/</url>
      <content type="html"><![CDATA[<p>rsync -avz -e “ssh -p 8050” root@138.128.198.223:/tmp/tesstrsync .</p>
<p>rsync -avz -e “ssh -p 8050” Msys.md root@138.128.198.223:/myblog/source/_posts/</p>
<p>rsync -avz -e “ssh -p 8050” * root@138.128.198.223/myblog/source/_posts/</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[module]]></title>
      <url>/2018/02/08/module/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title=" 简介 "></a><font color="#5CACEE"> 简介 </font></h1><blockquote>
<p>Oracle Database，又名Oracle RDBMS，或简称Oracle。是甲骨文公司的一款关系数据库管理系统。它是在数据库领域一直处于领先地位的产品。可以说Oracle数据库系统是目前世界上流行的关系数据库管理系统，系统可移植性好、使用方便、功能强，适用于各类大、中、小、微机环境。它是一种高效率、可靠性好的 适应高吞吐量的数据库解决方案。</p>
</blockquote>
<a id="more"></a>
<table>
<thead>
<tr>
<th>软件</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google云计算三大论文英文版</td>
<td><a href="https://pan.baidu.com/s/1dFOyXOX" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Google-File-System中文版</td>
<td><a href="https://pan.baidu.com/s/1eShdCKa" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Google-MapReduce中文版</td>
<td><a href="https://pan.baidu.com/s/1jIOoRaA" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Google-Bigtable中文版</td>
<td><a href="https://pan.baidu.com/s/1geX8jLL" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
</tbody>
</table>
<h1 id="一级目录"><a href="#一级目录" class="headerlink" title=" 一级目录 "></a><font color="#5CACEE"> 一级目录 </font></h1><h2 id="二级目录"><a href="#二级目录" class="headerlink" title=" 二级目录 "></a><font color="green"> 二级目录 </font></h2><h3 id="三级目录"><a href="#三级目录" class="headerlink" title=" 三级目录 "></a><font color="red"> 三级目录 </font></h3><h4 id="四级目录"><a href="#四级目录" class="headerlink" title="四级目录"></a>四级目录</h4><table>
<thead>
<tr>
<th>软件</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google云计算三大论文英文版</td>
<td><a href="https://pan.baidu.com/s/1dFOyXOX" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
</tbody>
</table>
<font face="黑体">我是黑体字</font>

<font face="微软雅黑">我是微软雅黑</font>

<font face="STCAIYUN">我是华文彩云</font>

<font color="#0099ff" size="7" face="黑体">color=#0099ff size=72<br>face=”黑体”</font>

<font color="#00ffff" size="72">color=#00ffff</font>

<font color="red">color=gray</font>

<p><font color="#5CACEE">What is Hexo?</font></p>
]]></content>
      
        <categories>
            
            <category> Oracle </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Database </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark深入]]></title>
      <url>/2018/02/04/Spark%E6%B7%B1%E5%85%A5/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title=" 简介 "></a><font color="#5CACEE"> 简介 </font></h1><p>Spark是一个解决大规模数据集运算分析的计算引擎，知其然更要知其所以然，深入了解编程模型，RDD原理，解析spark内核，能够让我们在一个更高的角度看程序运行，数据流动，而且现在对批处理有了其他的需求，比如sturcture stream实现的流处理，MLib实现的机器学习的分类聚类算法，对这种更高层次的spark应用的学习有助于更好的发挥spark的潜力，安装配置不值一提，具体应用才是画龙点睛。</p>
<p><a href="https://www.bilibili.com/video/av13765160/index_7.html?t=495" target="_blank" rel="external"><font color="#AAAAAA"> spark 教程 </font></a>讲的很透彻，已经刷了两遍，跟着做了一些实际操作，每一遍都有新的理解，学得越多越觉得自己懂得太少，奋斗吧少年！</p>
<a id="more"></a>
<p>深坑待填，关键是理论性东西写起来真的墨迹啊</p>
<h1 id="scala基础与实践"><a href="#scala基础与实践" class="headerlink" title=" scala基础与实践 "></a><font color="#5CACEE"> scala基础与实践 </font></h1><blockquote>
<p>scala是一门多范式的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。<br>scala用java开发，运行在java虚拟机上并兼容java程序，spark就是用scala开发的，用scala写spark的程序极为合适，其次是python和java。</p>
<p>不去学具体的使用技巧，不了解程序的内部原理，那么spark就只是一个软件，深入研究并自己写程序去测试spark的性能，它才会成为数据操控者手中的利剑，剑锋所指，一切真相无所遁形！额(⊙﹏⊙)，说人话就是:”用熟了之后做数据挖掘效率能手脚麻利一点”，<code>hiahiahia~~~</code></p>
</blockquote>
<h1 id="scala"><a href="#scala" class="headerlink" title=" scala "></a><font color="#5CACEE"> scala </font></h1><h1 id="spark编程模型"><a href="#spark编程模型" class="headerlink" title=" spark编程模型 "></a><font color="#5CACEE"> spark编程模型 </font></h1><h1 id="深入spark内核"><a href="#深入spark内核" class="headerlink" title=" 深入spark内核 "></a><font color="#5CACEE"> 深入spark内核 </font></h1><h1 id="spark-streaming"><a href="#spark-streaming" class="headerlink" title=" spark streaming "></a><font color="#5CACEE"> spark streaming </font></h1><h1 id="spark上运行机器学习，算法实现"><a href="#spark上运行机器学习，算法实现" class="headerlink" title=" spark上运行机器学习，算法实现 "></a><font color="#5CACEE"> spark上运行机器学习，算法实现 </font></h1><h1 id="shark多语言编程"><a href="#shark多语言编程" class="headerlink" title=" shark多语言编程 "></a><font color="#5CACEE"> shark多语言编程 </font></h1><p>rsync -avz -e “ssh -p 8050” root@138.128.198.223:/tmp/testi.docx </p>
]]></content>
      
        <categories>
            
            <category> Bigdata </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Framework </tag>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark实践]]></title>
      <url>/2018/02/02/Spark%E5%AE%9E%E8%B7%B5/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><p>Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎,一个用来实现快速而通用的集群计算的平台,扩展了广泛使用的MapReduce计算模型，能高效支持更多的计算模式，包括交互式查询和流处理。在处理大规模数据集的时候有优势，Spark的一个重要特点就是能够在内存中计算，因而比MapReduce更快，即使在磁盘上进行的复杂计算，Spark依然更加高效。</p>
<a id="more"></a>
<table>
<thead>
<tr>
<th>软件</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>jdk-8u161-linux-x64.tar.gz</td>
<td><a href="https://pan.baidu.com/s/1eTSOOQQ" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>hadoop-2.7.2.tar.gz</td>
<td><a href="https://pan.baidu.com/s/1dGssSkLX" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>scala-2.11.7.tgz</td>
<td><a href="https://pan.baidu.com/s/1dGf8lS" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>spark-2.2.0-bin-hadoop2.7.tgz</td>
<td><a href="https://pan.baidu.com/s/1eTDpAqm" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>hadoop-native-64-2.7.0.tar</td>
<td><a href="https://pan.baidu.com/s/1daOeqM" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>服务器</th>
<th>节点</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.4.50</td>
<td>SparkMaster</td>
</tr>
<tr>
<td>192.168.4.237</td>
<td>SparkWorker1</td>
</tr>
<tr>
<td>192.168.4.238</td>
<td>SparkWorker2</td>
</tr>
<tr>
<td>192.168.4.48</td>
<td>SparkWorker3</td>
</tr>
<tr>
<td>192.168.4.49</td>
<td>SparkWorker4</td>
</tr>
</tbody>
</table>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title=" Hadoop "></a><font color="#5CACEE"> Hadoop </font></h1><h2 id="运行环境配置"><a href="#运行环境配置" class="headerlink" title=" 运行环境配置 "></a><font color="green"> 运行环境配置 </font></h2><p>请务必关闭<strong>防火墙</strong>，包括<code>iptables</code>及<code>selinux</code></p>
<h3 id="java"><a href="#java" class="headerlink" title=" java "></a><font color="red"> java </font></h3><p>三台虚拟机均需配置java环境，下文所示环境是包括hadoop，scala，spark软件在内的环境变量最终形态，如果新玩家要入手，直接配置成这样纸，后面的软件注意存放在指定路径即可。</p>
<pre><code>$ tar xvf jdk-8u161-linux-x64.tar.gz  -C /usr/local/ 
$ vi /root/.bash_profile
$ source /root/.bash_profile
</code></pre><blockquote>
<pre><code>export PATH
export JAVA_HOME=/usr/local/jdk1.8.0_161
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib
export SCALA_HOME=/usr/local/scala-2.11.7
export SPARK_HOME=/usr/local/spark-2.2.0-bin-hadoop2.7
export PATH=$JAVA_HOME/bin:/usr/local/hadoop-2.7.2/bin:/usr/local/hadoop-2.7.2/sbin:$SCALA_HOME/bin:$SPARK_HOME/bin:$PATH
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native  
export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot;
</code></pre></blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517884683021.png" alt=""></p>
<h3 id="主机名称"><a href="#主机名称" class="headerlink" title=" 主机名称 "></a><font color="red"> 主机名称 </font></h3><p>各节点均要更改，图为主节点示例，需要修改<code>/etc/hosts</code>，<code>/etc/sysconfig/network</code>两个文件，注意<code>hosts</code>文件各节点一致，<code>network</code>文件各节点需分别修改成自己的<code>hostname</code></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517904904084.png" alt=""></p>
<h3 id="ssh"><a href="#ssh" class="headerlink" title=" ssh "></a><font color="red"> ssh </font></h3><p>在各虚拟机上执行命令生成密钥</p>
<pre><code># ssh-keygen 
</code></pre><p>ssh将各个机器的密钥拿来主节点（以下语句皆在SparkMaster上执行）合成authorized_keys，然后分发到各个节点</p>
<pre><code>$ ssh root@192.168.4.237 cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys

237替换成238，50，48，49依次执行，完成后会在主节点生成/root/.ssh/authorized_keys,是一份包含了五台机器公钥信息的文件

$ scp authorized_keys root@192.168.4.237:/root/.ssh/

237替换成238，50，48，49依次执行，将包含了五台服务器的公钥文件分发到所有服务器，所有节点之间都可以无密码ssh操作
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1517905440009.png" alt=""></p>
<blockquote>
<p>配置互信的原因:namenode(即主节点)如果没有对datanode(即数据节点)的ssh免登陆权限，那么namenode起每个datanode的服务都需要输入密码，多节点的情况极为影响效率，所以namenode与datanode间必须配置互信，而datanode之间没有ssh通信的需求，所以上文是一种绝对可行但相对麻烦和不必要的操作，如果多节点的大规模hadoop配置互信建议使用下面这种ssh自带的方法，可以使用类似ansible这样的工具批量执行。</p>
</blockquote>
<pre><code>$ ssh-keygen 

生成密钥

$ ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.4.50 

把datanode生成的公钥发送到namenode，namedode拥有所有datanode的公钥即可，datanode不必持有其他datanode或者namenode的公钥
</code></pre><h2 id="软件包解压"><a href="#软件包解压" class="headerlink" title=" 软件包解压 "></a><font color="green"> 软件包解压 </font></h2><p>在namenode解压并修改配置文件，用<code>rsync</code>把修改后的<code>/usr/local/hadoop-2.7.2</code>文件夹同步到其他节点</p>
<pre><code>$ tar xvf hadoop-2.7.2.tar.gz -C /usr/local/

$ mkdir -p {tmp,hdfs/{data,name}}
</code></pre><blockquote>
<p>tmp用来存储临时生成的文件</p>
<p>hdfs用来存储集群数据</p>
<p>hdfs/data用来存储真正的数据</p>
<p>hdfs/name用来存储文件系统元数据</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517907019997.png" alt=""></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title=" 修改配置文件 "></a><font color="green"> 修改配置文件 </font></h2><p>下列文件绝对路径:<code>/usr/local/hadoop-2.7.2/etc/hadoop/</code></p>
<h3 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title=" hadoop-env.sh "></a><font color="red"> hadoop-env.sh </font></h3><pre><code>将 export JAVA_HOME=${JAVA_HOME}

改成 export JAVA_HOME=/usr/local/jdk1.8.0_161
</code></pre><h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title=" core-site.xml "></a><font color="red"> core-site.xml </font></h3><pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://SparkMaster:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;file:/usr/local/hadoop-2.7.2/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;io.file.buffer.size&lt;/name&gt;
        &lt;value&gt;131072&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title=" mapred-site.xml "></a><font color="red"> mapred-site.xml </font></h3><pre><code>$ cp mapred-site.xml.template mapred-site.xml

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;SparkMaster:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;SparkMaster:19888&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title=" hdfs-site.xml "></a><font color="red"> hdfs-site.xml </font></h3><pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file:/usr/local/hadoop-2.7.2/hdfs/name&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file:/usr/local/hadoop-2.7.2/hdfs/data&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;SparkMaster:9001&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title=" yarn-site.xml "></a><font color="red"> yarn-site.xml </font></h3><pre><code>&lt;configuration&gt;
        &lt;property&gt;
               &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
               &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
               &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
               &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
               &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
               &lt;value&gt;SparkMaster:8032&lt;/value&gt;
       &lt;/property&gt;
       &lt;property&gt;
               &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
               &lt;value&gt;SparkMaster:8030&lt;/value&gt;
       &lt;/property&gt;
       &lt;property&gt;
               &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
               &lt;value&gt;SparkMaster:8031&lt;/value&gt;
       &lt;/property&gt;
       &lt;property&gt;
               &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
               &lt;value&gt;SparkMaster:8033&lt;/value&gt;
       &lt;/property&gt;
       &lt;property&gt;
               &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
               &lt;value&gt;SparkMaster:8088&lt;/value&gt;
       &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h3 id="slaves"><a href="#slaves" class="headerlink" title=" slaves "></a><font color="red"> slaves </font></h3><pre><code>SparkWorker1
SparkWorker2
SparkWorker3
SparkWorker4
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1517907253222.png" alt=""></p>
<p>所有节点的文件都需要是经过修改后的状态，利用rsync将namenode修改过的文件夹直接同步到其他节点</p>
<pre><code>$ rsync -av /usr/local/hadoop-2.7.2 SparkWorker1:/usr/local/hadoop-2.7.2

SparkWorker1替换成slaves里其他节点依次执行，所有节点都有了修改过配置文件的hadoop文件夹后集群准备工作完成。
</code></pre><h2 id="启动并验证服务"><a href="#启动并验证服务" class="headerlink" title=" 启动并验证服务 "></a><font color="green"> 启动并验证服务 </font></h2><pre><code>hadoop namenode -format  格式化

start-all.sh 或者 start-dfs.sh &amp;&amp; start-yarn.sh   
每个节点都有完整的配置文件和命令，任何节点都可以执行集群的起停操作，都可以成功启动hdfs和yarn   

jps  查看各个节点进程状态
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1517907563706.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517907627610.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517907799956.png" alt=""></p>
<p>hadoop集群已经正常<strong>启动</strong>。</p>
<h2 id="简单测试"><a href="#简单测试" class="headerlink" title=" 简单测试 "></a><font color="green"> 简单测试 </font></h2><pre><code>$ hadoop fs -put /tmp/input.txt /

上传待处理文件到hdfs中

$ hadoop jar /usr/local/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /input.txt /output.txt

调用安装包自带jar包对hdfs中存储的待处理文件执行词频统计，这里就是诸位大数据开发工程师大显身手的地方，写好的程序打成jar包放在这里供hadoop调用，examples是hadoop自带练手用的测试包。

$ hadoop fs -ls /output.txt

可以看到已经生成了一个包含着若干文件的output.txt文件夹，存放着调用jar包函数后输出的处理结果，给文件夹起output.txt这种名字，皮一下就很开心

$ hadoop fs -text /output.txt/part-r-00000
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1517909164567.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517909184848.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517909479584.png" alt=""></p>
<h1 id="Scala"><a href="#Scala" class="headerlink" title=" Scala "></a><font color="#5CACEE"> Scala </font></h1><h2 id="安装包"><a href="#安装包" class="headerlink" title=" 安装包 "></a><font color="green"> 安装包 </font></h2><pre><code>$ tar xvf /tmp/scala-2.11.7.tgz -C /usr/local

上传解压安装包到指定目录
</code></pre><h2 id="环境变量"><a href="#环境变量" class="headerlink" title=" 环境变量 "></a><font color="green"> 环境变量 </font></h2><pre><code>$ vi /root/.bash_profile

添加 /usr/local/scala-2.11.7/bin 到PATH路径中
</code></pre><h2 id="同步并验证"><a href="#同步并验证" class="headerlink" title=" 同步并验证 "></a><font color="green"> 同步并验证 </font></h2><pre><code>scala -version
</code></pre><p>一个词，<code>rsync</code>，有点灵性啊同学们!</p>
<h1 id="Spark"><a href="#Spark" class="headerlink" title=" Spark "></a><font color="#5CACEE"> Spark </font></h1><h2 id="安装包-1"><a href="#安装包-1" class="headerlink" title=" 安装包 "></a><font color="green"> 安装包 </font></h2><pre><code>$ tar xvf /tmp/spark-2.2.0-bin-hadoop2.7.tgz -C /usr/local
</code></pre><h2 id="环境变量及配置文件"><a href="#环境变量及配置文件" class="headerlink" title=" 环境变量及配置文件 "></a><font color="green"> 环境变量及配置文件 </font></h2><pre><code>$ vi /root/.bash_profile

添加 /usr/local/spark-2.2.0-bin-hadoop2.7/bin到环境变量
</code></pre><h3 id="spark-env-sh"><a href="#spark-env-sh" class="headerlink" title=" spark-env.sh "></a><font color="red"> spark-env.sh </font></h3><pre><code>export JAVA_HOME=/usr/local/jdk1.8.0_161

export SCALA_HOME=/usr/scala-2.11.7

export HADOOP_HOME=/usr/local/hadoop-2.7.2

export HADOOP_CONF_DIR=/usr/local/hadoop-2.7.2/etc/hadoop

export SPARK_MASTER_IP=SparkMaster

export SPARK_WORKER_MEMORY=4g

export SPARK_WORKER_CORES=2

export SPARK_WORKER_INSTANCES=1
</code></pre><h3 id="slaves-1"><a href="#slaves-1" class="headerlink" title=" slaves "></a><font color="red"> slaves </font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1517974200450.png" alt=""></p>
<h2 id="同步并验证-1"><a href="#同步并验证-1" class="headerlink" title=" 同步并验证 "></a><font color="green"> 同步并验证 </font></h2><pre><code>将修改过配置文件的文件夹全部同步到数据节点
</code></pre><blockquote>
<p>$ start-dfs.sh</p>
<p>spark只使用hdfs文件系统，并不用启动所有功能</p>
<p>$ /usr/local/spark-2.2.0-bin-hadoop2.7/sbin/start-all.sh</p>
<p>启动spark集群，建议使用绝对路径</p>
<p>成功启动后使用jps可以在namenode看到</p>
</blockquote>
<pre><code>30049 Jps
29655 ResourceManager
29501 SecondaryNameNode
29311 NameNode
</code></pre><blockquote>
<p>可以在datanode看到</p>
</blockquote>
<pre><code>4208 Jps
3937 DataNode
4042 NodeManager
</code></pre><p>至此<strong>spark集群</strong>全部搭建完成<br><img src="http://p09u6sy9g.bkt.clouddn.com/1517912187159.png" alt=""></p>
<blockquote>
<p>可以通过spark的webui界面访问控制台</p>
<p>可以通过spark-shell执行各种操作，执行transcation  action任务，对存放在hdfs里的数据集进行分词，统计，排序</p>
<p>可以执行用python，scala，java等语言打包好的jar包程序</p>
</blockquote>
<pre><code>ENJOY IT!
</code></pre><h1 id="遇到的坑"><a href="#遇到的坑" class="headerlink" title=" 遇到的坑 "></a><font color="#5CACEE"> 遇到的坑 </font></h1><p>1.请务必关闭防火墙，包括iptables和selinux，否则会导致集群无法通信，页面无法访问等报错，如<code>java.net.NoRouteToHostException:没有找到主机的路由</code></p>
<p>2.启动后有警告<code>Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code>，因为Apache提供的hadoop本地库是32位的，而在64位的服务器上就会有问题，因此需要自己编译64位的版本，解决方案是找个包，解压到目录并修改环境变量，操作后问题解决，原作者环境跟我的环境不一样，不确定是不是所有人都会碰到这个问题</p>
<pre><code>$ tar -xvf hadoop-native-64-2.7.0.tar -C /usr/local/hadoop-2.7.2/lib/native 

$ tar -xvf hadoop-native-64-2.7.0.tar -C /usr/local/hadoop-2.7.2/lib
</code></pre><p>3.第一次启动后进程都正常，页面无法访问，查看监听状态发现监听到了ipv6的端口，hadoop的配置文件明明标注的是监听到ipv4的端口，解决方案如下。</p>
<pre><code>vi /etc/sysctl.conf
添加以下内容并执行stop-all.sh和start-all.sh重启hadoop服务
#disable ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
</code></pre><p>4.数据节点jps没有datanode进程的情况</p>
<p>多次format文件系统可能会出现datanode无法启动的情况，<strong>解决方案是删除数据节点的hdfs及tmp目录，重新启动即可。</strong></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517971666429.png" alt=""></p>
<blockquote>
<p>原因是执行<code>hadoop namenode -format</code>后会在<code>namenode</code>的<code>/usr/lcoal/hadoop-2.7.2/hdfs/name/current/</code>文件夹下生成记录了<code>namespaceID</code>，<code>clusterID</code>及<code>blockpoolID</code>的<code>VERSION</code>文件，然后执行<code>start-dfs.sh</code>命令启动hdfs，这时datanode的<code>/usr/local/hadoop-2.7.2/hdfs/data/</code>文件夹下会生成记录了集群信息的文件。</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517970828891.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1517971096804.png" alt=""></p>
<blockquote>
<p>hadoop启动关闭hdfs时需要读取namenode及datanode的集群信息，二次format的时候namenode的相关信息会自动更新，但datanode的原有信息不会自动删除，启动的时候namenode优先读取该节点原有信息，这样本来准备起datanode，一看有记录，要写入的信息不写了，按原有记录来，结果原有记录的信息是format之前集群的信息，hadoop以为那是其他集群的数据节点，自然不会带起来datanode进程。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Bigdata </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Framework </tag>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NoSQL简介]]></title>
      <url>/2018/01/23/NoSQL/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>本文主要参考<a href="http://www.runoob.com/mongodb/nosql.html" target="_blank" rel="external"><font color="#AAAAAA">菜鸟教程</font></a>，原博文清晰明了，可以自行前往，写在这里是以手连心加深印象，同时把这些信息抓回来作为以博客为载体的个人技能图的重要组成部分。</p>
<p>NoSQL(NoSQL = Not Only SQL )，意即”不仅仅是SQL”。</p>
<p>现代计算系统上每天网络上都会产生庞大的数据量，这些数据很大一部分是由关系数据库RDBMS处理，实践证明关系模型非常适合于客户端服务器编程，是结构化数据存储在网络和商务应用的主导技术。</p>
<p>NoSQL是另一种数据组织形式，早期提出至09年趋势高涨，NoSQL相关的非关系型数据库在存储处理当前互联网快速产生，日益庞大，形式多样的数据方面有巨大优势，发展迅速。</p>
</blockquote>
<a id="more"></a>
<h1 id="NoSQL简史"><a href="#NoSQL简史" class="headerlink" title=" NoSQL简史 "></a><font color="#5CACEE"> NoSQL简史 </font></h1><p>NoSQL一词最早出现在1998年，是Carlo Strozzi开发的一个轻量，开源，不提供SQL功能的关系数据库；</p>
<p>2009年，有一次关于分布式开源数据库的讨论，有人再次提出了NoSQL的概念，主要指非关系型，分布式，不提供ACID的数据库设计模式；</p>
<p>2009年，亚特兰大举行的”no:sql(east)”讨论会是一个里程碑，其口号”select fun, profit from real_world where relational = false”，因此对NoSQL最普遍的解释是”非关系型的”，强调key-values stores和文档数据库的优点，而不是单纯的反对RDBMS。</p>
<p>时至今日，各种NoSQL数据库已经是大数据领域各种数据分布式存储的基石。</p>
<h1 id="NoSQL数据库分类"><a href="#NoSQL数据库分类" class="headerlink" title=" NoSQL数据库分类 "></a><font color="#5CACEE"> NoSQL数据库分类 </font></h1><table>
<thead>
<tr>
<th>类型</th>
<th>代表数据库</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>列存储</td>
<td>Hbase/Cassandra/Hypertable</td>
<td>按列存储，方便存储结构化和半结构化数据，方便做数据压缩，在某一列或者某几列的查询中有巨大的IO优势</td>
</tr>
<tr>
<td>文档存储</td>
<td>MongoDB/CouchDB</td>
<td>用类似json的格式存储文档，可以对某些字段建立索引，实现关系数据库的某些功能</td>
</tr>
<tr>
<td>key-value存储</td>
<td>Redis/MemcacheDB</td>
<td>存储的是key-value对，不管value的格式，可以通过key快速查询value</td>
</tr>
<tr>
<td>图存储</td>
<td>Neo4J/FlockDB</td>
<td>图形关系的最佳存储方案</td>
</tr>
<tr>
<td>对象存储</td>
<td>db4o/Versant</td>
<td>通过对象的方式存储数据，用类似面向对象语言的语法操作数据库</td>
</tr>
<tr>
<td>xml数据库</td>
<td>BaseX/Berkeley XML DB</td>
<td>高效存储XML数据，支持XML内部查询语法，比如XQuery，Xpath</td>
</tr>
</tbody>
</table>
<h1 id="RDBMS和NoSQL的规则"><a href="#RDBMS和NoSQL的规则" class="headerlink" title=" RDBMS和NoSQL的规则 "></a><font color="#5CACEE"> RDBMS和NoSQL的规则 </font></h1><h2 id="ACID"><a href="#ACID" class="headerlink" title=" ACID "></a><font color="green"> ACID </font></h2><p>关系型数据库有一个很重要的概念:事务(transaction)，类似现实中的交易，遵循ACID:</p>
<h3 id="A-Atomicity-原子性"><a href="#A-Atomicity-原子性" class="headerlink" title=" A-Atomicity 原子性 "></a><font color="red"> A-Atomicity 原子性 </font></h3><p>事务要么不做，要么做完，事务成功的条件是事务里所有操作均成功完成，只要有一个操作失败，整个事务便失败回滚。<br>比如银行转账，A账户转B账号，分为两个步骤:<br>1.从A账号取出100元<br>2.往B账号转入100元<br>银行的数据库处理该事务，要么两步一起完成，事务提交，任何一步出问题事务都会回滚，如果第一步未完成那么事务失败，第二步未完成，B没收到钱但A少了100元，事务会回滚到未转账状态。</p>
<h3 id="C-Consistency-一致性"><a href="#C-Consistency-一致性" class="headerlink" title=" C-Consistency 一致性 "></a><font color="red"> C-Consistency 一致性 </font></h3><p>数据库一直处于一致的状态，事务的运行不会改变原本的一致性约束。<br>例如某表上有完整性约束”a + b = 10”，如果一个事务改变了a，那么b必定会发生改变，使得事务结束后依然满足该约束，否则事务失败</p>
<h3 id="I-Isolation-独立性"><a href="#I-Isolation-独立性" class="headerlink" title=" I-Isolation 独立性 "></a><font color="red"> I-Isolation 独立性 </font></h3><p>并发的事务之间不会互相影响，如果A事务访问的数据正在被B事务修改，只要B事务未提交，A访问的数据就不会受到影响</p>
<h3 id="D-Durability-持久性"><a href="#D-Durability-持久性" class="headerlink" title=" D-Durability 持久性 "></a><font color="red"> D-Durability 持久性 </font></h3><p>一旦事务提交，所有的修改将会永久保存在数据库上，即使宕机也不会丢失，除非进行数据库恢复</p>
<h2 id="BASE"><a href="#BASE" class="headerlink" title=" BASE "></a><font color="green"> BASE </font></h2><p>Basically Available, Soft-state, Eventually Consistent</p>
<p>Basically Availble –基本可用</p>
<p>Soft-state –软状态/柔性事务。 “Soft state” 可以理解为”无连接”的, 而 “Hard state” 是”面向连接”的</p>
<p>Eventual Consistency –最终一致性 最终一致性， 也是是 ACID 的最终目的。</p>
<h2 id="CAP"><a href="#CAP" class="headerlink" title=" CAP "></a><font color="green"> CAP </font></h2><p>计算机科学中，<a href="http://blog.csdn.net/chen77716/article/details/30635543" target="_blank" rel="external"><font color="#AAAAAA"> CAP定理 </font></a>揭示了分布式系统的本质，并给出了设计准则，它指出任何分布式计算系统不能同时满足<br>一致性(Consistency) - 所有节点在同一时间具有相同的数据<br>可用性(Availability) - 保证每个请求都有响应，无论响应成功还是失败<br>分区容错性(Partition tolerance) - 系统中任意信息的丢失或失败不会影响系统的继续运作</p>
<p>CA without P,如果不要求P(分区)，那么CA(强一致性和可用性)是可以保证的，但分区是始终存在的问题，因此CA系统更多的是允许分区后各子系统依然保证CA。</p>
<p>CP without A，如果不要求A，相当于每个请求都需要server之间强一致，而P会导致时间无限延长，因此CP也是可以保证的，很多传统的数据库分布式事务都属于这种模式</p>
<p>AP without C，要高可用并允许分区，则需放弃一致性，一旦分区发生，节点间可能失去联系，为了高可用，每个节点只能用本地数据提供服务，而这会导致全局数据的不一致性，众多NoSQL数据库都属于此类</p>
<p>因此，根据CAP原理将数据库分成满足CA,CP,AP的三大类:</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516593700888.png" alt=""></p>
<h1 id="为什么用NoSQL"><a href="#为什么用NoSQL" class="headerlink" title=" 为什么用NoSQL "></a><font color="#5CACEE"> 为什么用NoSQL </font></h1><h2 id="RDBMS"><a href="#RDBMS" class="headerlink" title=" RDBMS "></a><font color="green"> RDBMS </font></h2><ul>
<li>高度组织化结构化数据 </li>
<li>结构化查询语言（SQL） (SQL) </li>
<li>数据和关系都存储在单独的表中。 </li>
<li>数据操纵语言，数据定义语言 </li>
<li>严格的一致性</li>
<li>基础事务</li>
</ul>
<h2 id="NoSQL"><a href="#NoSQL" class="headerlink" title=" NoSQL "></a><font color="green"> NoSQL </font></h2><ul>
<li>代表着不仅仅是SQL</li>
<li>没有声明性查询语言</li>
<li>没有预定义的模式</li>
<li>键 - 值对存储，列存储，文档存储，图形数据库</li>
<li>最终一致性，而非ACID属性</li>
<li>非结构化和不可预知的数据</li>
<li>CAP定理 </li>
<li>高性能，高可用性和可伸缩性</li>
</ul>
<p>优点:</p>
<p>1.高可扩展性</p>
<p>2.分布式计算</p>
<p>3.低成本</p>
<p>4.架构灵活，可以处理半结构化/非结构化数据</p>
<p>5.不用处理复杂的关系模型</p>
<p>缺点:</p>
<p>1.没有关系型数据库发展得那么成熟</p>
<p>2.查询功能有限</p>
<p>3.是一种最终一致性的系统，它们为了高的可用性牺牲了一部分的一致性</p>
<p>可以通过第三方平台（如：Google,Facebook等）可以很容易的访问和抓取数据。用户的个人信息，社交网络，地理位置，用户生成的数据和用户操作日志已经成倍的增加。我们如果要对这些用户数据进行挖掘，那SQL数据库已经不适合这些应用了, NoSQL数据库的发展也却能很好的处理这些大的数据。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516691622785.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> NoSQL </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Theory </tag>
            
            <tag> Database </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mongodb补充]]></title>
      <url>/2018/01/19/mongodb%E8%A1%A5%E5%85%85/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><p>MongoDB 是一个由 C++ 语言编写的基于分布式文件存储的数据库，旨在为 WEB 应用提供可扩展的高性能数据存储解决方案，这里简要介绍一下基本操作和存储原理，勉强能够应付日常工作。如果主要工作环境和业务都是mongo，那么就需要深入研究了，本文是远远不够的。</p>
<a id="more"></a>
<h1 id="P1（基础阶段）"><a href="#P1（基础阶段）" class="headerlink" title=" P1（基础阶段） "></a><font color="#5CACEE"> P1（基础阶段） </font></h1><h2 id="增"><a href="#增" class="headerlink" title=" 增 "></a><font color="green"> 增 </font></h2><blockquote>
<p>db.COLLECTION_NAME.insert(document)</p>
<p>例:</p>
<pre><code>db.col.insert({title: &apos;MongoDB 教程&apos;, 
    description: &apos;MongoDB 是一个 Nosql 数据库&apos;,
    by: &apos;菜鸟教程&apos;,
    url: &apos;http://www.runoob.com&apos;,
    tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;],
    likes: 100
})
</code></pre></blockquote>
<h2 id="删"><a href="#删" class="headerlink" title=" 删 "></a><font color="green"> 删 </font></h2><p>db.collection.remove(<br>query,<br>justOne<br>)</p>
<pre><code>db.col.remove({&apos;title&apos;:&apos;MongoDB 教程&apos;})

db.col.remove({})

db.col.find()
</code></pre><h2 id="改"><a href="#改" class="headerlink" title=" 改 "></a><font color="green"> 改 </font></h2><blockquote>
<p>db.collection.update(<br>   <query>,<br>   <update>,<br>   {<br>     upsert: <boolean>,<br>     multi: <boolean>,<br>     writeConcern: <document><br>   }<br>)</document></boolean></boolean></update></query></p>
<p>例:</p>
<p>db.col.update({‘title’:’MongoDB 教程’},{$set:{‘title’:’MongoDB’}})</p>
<p>db.col.update({‘title’:’MongoDB 教程’},{$set:{‘title’:’MongoDB’}},{multi:true})</p>
<p>db.col.save({<br>    “_id” : ObjectId(“56064f89ade2f21f36b03136”),<br>    “title” : “MongoDB”,<br>    “description” : “MongoDB 是一个 Nosql 数据库”,<br>    “by” : “Runoob”,<br>    “url” : “<a href="http://www.runoob.com" target="_blank" rel="external">http://www.runoob.com</a>“,<br>    “tags” : [<br>            “mongodb”,<br>            “NoSQL”<br>    ],<br>    “likes” : 110<br>})</p>
</blockquote>
<h2 id="查"><a href="#查" class="headerlink" title=" 查 "></a><font color="green"> 查 </font></h2><blockquote>
<p>MongoDB 查询文档使用 find() 方法,以非结构化的方式来显示所有文档。</p>
<p>db.collection.find(query, projection)</p>
<p>可以使用where，大于等于小于，与或非等条件进行查询，具体语句自行查找</p>
</blockquote>
<h2 id="排序"><a href="#排序" class="headerlink" title=" 排序 "></a><font color="green"> 排序 </font></h2><blockquote>
<p>db.COLLECTION_NAME.find().sort({KEY:1})</p>
</blockquote>
<pre><code>db.col.find({},{&quot;title&quot;:1,_id:0}).sort({&quot;likes&quot;:-1})
</code></pre><h2 id="索引"><a href="#索引" class="headerlink" title=" 索引 "></a><font color="green"> 索引 </font></h2><blockquote>
<p>db.COLLECTION_NAME.ensureIndex({KEY:1})</p>
</blockquote>
<pre><code>db.col.ensureIndex({&quot;title&quot;:1})
</code></pre><h2 id="聚合"><a href="#聚合" class="headerlink" title=" 聚合 "></a><font color="green"> 聚合 </font></h2><blockquote>
<p>MongoDB中聚合(aggregate)主要用于处理数据(诸如统计平均值,求和等)，并返回计算后的数据结果。有点类似sql语句中的 count(*)。</p>
<p>db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION)</p>
</blockquote>
<pre><code>db.mycol.aggregate([{$group : {_id : &quot;$by_user&quot;, num_tutorial : {$sum : 1}}}])
</code></pre><h2 id="mongo集群搭建"><a href="#mongo集群搭建" class="headerlink" title=" mongo集群搭建 "></a><font color="green"> mongo集群搭建 </font></h2><blockquote>
<p>大概就是副本集，主从，sharding，目的是将数据同步到多个服务器，复制提供数据的冗余备份，从而提高了数据的可用性， 并保证数据的安全性，主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。</p>
</blockquote>
<h2 id="mongo备份恢复"><a href="#mongo备份恢复" class="headerlink" title=" mongo备份恢复 "></a><font color="green"> mongo备份恢复 </font></h2><blockquote>
<p>在另一篇博客里有应用场景的命令格式，大概就是用mongodump和mongorestor两个命令实现数据导出到备份集和导入</p>
</blockquote>
<h2 id="mongo监控"><a href="#mongo监控" class="headerlink" title=" mongo监控 "></a><font color="green"> mongo监控 </font></h2><p>mongostat命令是mongo自带的状态检测工具，可以间隔固定时间获取并输出mongodb的当前运行状态，数据库变慢或者有异常的首选操作</p>
<h1 id="P2-稍高一点"><a href="#P2-稍高一点" class="headerlink" title=" P2(稍高一点) "></a><font color="#5CACEE"> P2(稍高一点) </font></h1><h2 id="mongodb-map-reduce"><a href="#mongodb-map-reduce" class="headerlink" title=" mongodb map reduce "></a><font color="green"> mongodb map reduce </font></h2><p>Map-Reduce是一种计算模型，简单的说就是将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果（REDUCE），MongoDB提供的Map-Reduce非常灵活，对于大规模数据分析也相当实用</p>
<p>以下是MapReduce的基本语法：</p>
<pre><code>&gt;db.collection.mapReduce(
   function() {emit(key,value);},  //map 函数
   function(key,values) {return reduceFunction},   //reduce 函数
   {
  out: collection,
  query: document,
  sort: document,
  limit: number
   }
)
</code></pre><p>使用 MapReduce 要实现两个函数 Map 函数和 Reduce 函数,Map 函数调用 emit(key, value), 遍历 collection 中所有的记录, 将 key 与 value 传递给 Reduce 函数进行处理。</p>
<p>Map 函数必须调用 emit(key, value) 返回键值对。</p>
<p>参数说明:</p>
<ul>
<li>map ：映射函数 (生成键值对序列,作为 reduce 函数参数)。</li>
<li>reduce 统计函数，reduce函数的任务就是将key-values变成key-value，也就是把values数组变成一个单一的值value。。</li>
<li>out 统计结果存放集合 (不指定则使用临时集合,在客户端断开后自动删除)。</li>
<li>query 一个筛选条件，只有满足条件的文档才会调用map函数。（query。limit，sort可以随意组合）</li>
<li>sort 和limit结合的sort排序参数（也是在发往map函数前给文档排序），可以优化分组机制</li>
<li>limit 发往map函数的文档数量的上限（要是没有limit，单独使用sort的用处不大）</li>
</ul>
<p>以下实例在集合 orders 中查找 status:”A” 的数据，并根据 cust_id 来分组，并计算 amount 的总和。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516698348837.png" alt=""></p>
<p>操作实例</p>
<p>准备数据集</p>
<pre><code>db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;mark&quot;,
   &quot;status&quot;:&quot;active&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;mark&quot;,
   &quot;status&quot;:&quot;active&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;mark&quot;,
   &quot;status&quot;:&quot;active&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;mark&quot;,
   &quot;status&quot;:&quot;active&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;mark&quot;,
   &quot;status&quot;:&quot;disabled&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;runoob&quot;,
   &quot;status&quot;:&quot;disabled&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;runoob&quot;,
   &quot;status&quot;:&quot;disabled&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
db.posts.insert({
   &quot;post_text&quot;: &quot;菜鸟教程，最全的技术文档。&quot;,
   &quot;user_name&quot;: &quot;runoob&quot;,
   &quot;status&quot;:&quot;active&quot;
})
WriteResult({ &quot;nInserted&quot; : 1 })
</code></pre><p>在 posts 集合中使用 mapReduce 函数来选取已发布的文章(status:”active”)，并通过user_name分组，计算每个用户的文章数</p>
<pre><code>db.posts.mapReduce( 
   function() { emit(this.user_name,1); }, 
   function(key, values) {return Array.sum(values)}, 
  {  
 query:{status:&quot;active&quot;},  
 out:&quot;post_total&quot; 
  }
)
</code></pre><p>结果如下</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516700750023.png" alt=""></p>
<p>结果表明，共有 5 个符合查询条件（status:”active”）的文档， 在map函数中生成了 5 个键值对文档，最后使用reduce函数将相同的键值分为 2 组。</p>
<p>用类似的方式，MapReduce可以被用来构建大型复杂的聚合查询。</p>
<p>Map函数和Reduce函数可以使用 JavaScript 来实现，使得MapReduce的使用非常灵活和强大。</p>
<p>以小见大，mongo集群的存储性能，可扩展性，对mapreduce的支持，使得分布式集群搭建后运行各种数据分析挖掘算法来处理海量数据有了可靠的保证。</p>
<h2 id="mongodb-全文检索"><a href="#mongodb-全文检索" class="headerlink" title=" mongodb 全文检索 "></a><font color="green"> mongodb 全文检索 </font></h2><p>全文检索对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。</p>
<p>这个过程类似于通过字典中的检索字表查字的过程。</p>
<p>MongoDB 从 2.4 版本开始支持全文检索，目前支持15种语言(暂时不支持中文)的全文索引。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516701675326.png" alt=""></p>
<h2 id="mongodb-正则表达式"><a href="#mongodb-正则表达式" class="headerlink" title=" mongodb 正则表达式 "></a><font color="green"> mongodb 正则表达式 </font></h2><p>正则表达式是使用单个字符串来描述，匹配一系列符合某个语法规则的字符串。</p>
<p>正则表达式在文本处理方面极为实用，很多语言都支持利用正则表达式进行字符串操作</p>
<p>mongodb使用$regex操作符来设置匹配字符串的正则表达式</p>
<p>可以设置 $options 为 $i 使正则匹配忽略大小写</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516759167493.png" alt=""></p>
<p>如果你的文档中字段设置了索引，那么使用索引相比于正则表达式匹配查找所有的数据查询速度更快</p>
<h2 id="mongodb-管理工具-Rockmongo"><a href="#mongodb-管理工具-Rockmongo" class="headerlink" title=" mongodb 管理工具: Rockmongo "></a><font color="green"> mongodb 管理工具: Rockmongo </font></h2><p><a href="https://github.com/iwind/rockmongo.git" target="_blank" rel="external"><font color="#AAAAAA">rockmongo</font></a>是php写的一个mongodb管理工具，可以用来管理服务，数据库，集合，文档，索引等，具体使用方法等用到了学就是，界面管理方法想来也是跟Plsqldeveloper和navicat那些差不多的页面版</p>
<h1 id="P3-再高一点点"><a href="#P3-再高一点点" class="headerlink" title=" P3(再高一点点) "></a><font color="#5CACEE"> P3(再高一点点) </font></h1><p>mongo是常用的面向文档非关系数据库，主要应用场景在微博，博客等消息存储业务，数据与金融等传统行业比起来没有那么重要，对事务要求相对不高，这时候用mongo比关系型数据库更合适，因为关系型数据库每次操作都有ACK，mongo省去了这一步，大大提高存储性能，同时设计时就考虑了廉价设备的容错和业务增长时的可扩展性。</p>
<p>在其他的博客内容对mongo的集群搭建有了一定的认识，这里通过一种副本集与分片混合部署的方案和数据存取，数据存储，对mongo的应用做进一步的介绍。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516760767229.png" alt=""></p>
<p>副本集中每个节点存储的数据都是相同的，相当于主备方式的数据冗余，分片是为了数据拓展，按照片键进行节点划分，数据根据片键存储到对应服务器上。</p>
<p>mongo的集群中有三类角色:实际数据存储节点，配置文件存储节点和路由介入节点。</p>
<blockquote>
<p>ps:在另一个介绍集群搭建方案的博客里，副本集配置里除了存储节点还有一个arbiter节点，负责节点故障的时候仲裁主节点切换，实测有该节点时双节点中主节点停/起副节点会自动切主备，没有则主掉了副节点还是副节点，不会自动切换</p>
</blockquote>
<p>客户端与路由节点连接，从配置节点上查询数据，根据查询结果到实际的存储节点上查询和存储数据。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516761696689.png" alt=""></p>
<blockquote>
<p>客户端发起写操作请求，路由节点接到请求后查询配置服务器，得到有存储空间的服务器，路由节点把写入操作转发给由副本集组成的数据存储服务器，管理过程类似hdfs中master节点对chunk server的管理</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516761711577.png" alt=""></p>
<blockquote>
<p>客户端发起读操作请求，路由节点接到请求后查询配置服务器，根据存储服务器中的记录，返回目标数据的存储服务器路径大小等信息，路由节点转发读操作到存储服务器，获取信息后路由服务器将查询结果返回给客户端</p>
</blockquote>
<p>副本集内部的写操作</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516762205709.png" alt=""></p>
<blockquote>
<p>写操作只写到主节点当中，由主节点以异步的方式同步到从节点</p>
</blockquote>
<p>副本集内部的读操作</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516762230222.png" alt=""></p>
<blockquote>
<p>可以从任意节点读取数据，也可以指定具体到哪个节点</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516763021610.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516763044775.png" alt=""></p>
<h1 id="P4-可以说相当高了"><a href="#P4-可以说相当高了" class="headerlink" title=" P4(可以说相当高了) "></a><font color="#5CACEE"> P4(可以说相当高了) </font></h1><h2 id="存储引擎-wiredTiger"><a href="#存储引擎-wiredTiger" class="headerlink" title="存储引擎:wiredTiger"></a><font color="green">存储引擎:<a href="http://www.mongoing.com/archives/2540" target="_blank" rel="external">wiredTiger</a></font></h2><p>按照Mongodb默认的配置，WiredTiger的写操作会先写入Cache，并持久化到WAL(Write ahead log)，每60s或log文件达到2GB时会做一次Checkpoint，将当前的数据持久化，产生一个新的快照。Wiredtiger连接初始化时，首先将数据恢复至最新的快照状态，然后根据WAL恢复数据，以保证存储可靠性</p>
<p>所有write请求都基于”文档级别”的lock，因此多个客户端可以同时更新一个collection中的不同文档，这种更细颗粒度的lock，可以支撑更高的读写负载和并发量，因为对于production环境，更多的CPU可以有效提升wiredTiger性能，因为它是多线程IO。</p>
<h2 id="架构模式"><a href="#架构模式" class="headerlink" title="架构模式"></a><font color="green">架构模式</font></h2><p>Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群</p>
<p>Sharding cluster：分片集群，数据水平扩展的手段之一,replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。</p>
<p>系统配置：</p>
<pre><code>- 建议mongodb部署在linux系统上，较高版本，选择合适的底层文件系统（ext4），开启合适的swap空间  

- 无论是MMAPV1或者wiredTiger引擎，较大的内存总能带来直接收益。

- 对数据存储文件关闭“atime”（文件每次access都会更改这个时间值，表示文件最近被访问的时间），可以提升文件访问效率。 

- ulimit参数调整，这个在基于网络IO或者磁盘IO操作的应用中，通常都会调整，上调系统允许打开的文件个数（ulimit -n 65535）
</code></pre><h2 id="数据文件存储原理"><a href="#数据文件存储原理" class="headerlink" title="数据文件存储原理"></a><font color="green">数据文件存储原理</font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516777869529.png" alt=""></p>
<h3 id="Data-Files"><a href="#Data-Files" class="headerlink" title="Data Files"></a><font color="red">Data Files</font></h3><p>mongodb的数据会保存在底层文件系统中，比如”dbpath=/usr/local/mongodb/master”，创建一个database为”runoob”，collection为”col”，然后插入若干documents，可以看到如下列表</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516778681686.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516778713479.png" alt=""></p>
<p>可以看到数据文件所在目录”/usr/local/mongodb/master”下面生成了”runoob”文件夹，里面存放有若干collection文件，数据文件从16M开始，每次扩张一倍(16M，32M，64M，128M…)，默认情况下迟迟单个data file最大尺寸为2G，smallfile设置后限定512M，每个database最多支持16000个数据文件，约32T，smallfiles设置后单个database最大容量8T</p>
<p>一个database中所有的collections及索引信息会分散存储在多个数据文件中，没有像SQL数据库一样每个表的数据索引分别存储；</p>
<p>数据分块的单位是extent(范围，区域)，extent中可以保存collection数据或者index数据，每个extent包含多条document，大小不等，一个extent只能保存同一个collection的数据，不同collections数据分布在不同extents中，indexs也保存在各自的extent中，一个collection由一个或多个extent构成，最小size8K，最大2G，这些extent分散在多个datafile中，换句话说，一个datafile可能包含多个collection的数据，由不同collection的extent组成，但一个extent不会跨越两个datafile</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516787466812.png" alt=""></p>
<p>举个栗子（吼吼），两个数据文件my-db.1和my-db.2里存放A和B两张表的数据，AB两张表上的document和index存放在一个个小的extent里面，这些extent并不是各自集中存放，而是散布在两个数据文件里面</p>
<p>在每个database的namespace文件中，比如test.ns文件中，每个collection只保存了第一个extent的位置信息，并不保存所有的extents列表，但每个extent都维护者一个链表关系，即每个extent都在其header信息中记录了此extent的上一个、下一个extent的位置信息，这样当对此collection进行scan操作时（比如全表扫描），可以提供很大的便利性。</p>
<p>由存储机制可以很容易想到，删除document会导致磁盘碎片，有些update也会导致磁盘碎片，比如update导致文档尺寸变大，进而超过原来分配的空间；当有新的insert操作时，mongodb会检测现有的extents中是否合适的碎片空间可以被重用，如果有，则重用这些fragment，否则分配新的存储空间。磁盘碎片对write操作有一定的性能影响，而且会导致磁盘空间浪费；</p>
<p> 如果database已经运行一段时间，数据已经有很大的磁盘碎片（storageSize与dataSize比较），可以通过mongodump将指定database的所有数据导出，然后将原有的db删除，再通过mongorestore指令将数据重新导入</p>
<h3 id="Namespace文件"><a href="#Namespace文件" class="headerlink" title="Namespace文件"></a><font color="red">Namespace文件</font></h3><p>对于namespace文件，比如“test.ns”文件，默认大小为16M，此文件中主要用于保存“collection”、index的命名信息，比如collection的“属性”信息、每个索引的属性类型等，如果你的database中需要存储大量的collection（比如每一小时生成一个collection，在数据分析应用中），那么我们可以通过配置文件“nsSize”选项来指定，参见<a href="http://blog.csdn.net/sun491922556/article/details/74973191" target="_blank" rel="external">某博客</a>。</p>
<h3 id="journal文件"><a href="#journal文件" class="headerlink" title="journal文件"></a><font color="red">journal文件</font></h3><p>journal日志保存在dbpath下“journal”子目录中，一般会有三个journal文件，journal文件中保存了write操作的记录，每条记录中包含write操作内容之外，还包含一个“lsn”（last sequence number），表示此记录的ID</p>
<p> journal是一个预写事务日志，来确保数据持久性，存储引擎每隔60s(默认/可调)或者待写入数据达到2G，mongo将对journal文件提交一个checkpoint检测点，将内存中的数据变更flush到磁盘的数据文件中，并做一个标记点，表示此前的数据已经持久存储在数据文件中，检测点创建后，journal日志清空，后续数据更改存在于内存和journal日志。</p>
<p> 例如write操作首先被写入journal日志，然后在内存中变更数据，数据量积累或者时间间隔条件满足后触发检测点，数据flush到数据文件。即检测点之前的数据只是在journal中持久存储，并没有写入数据文件，延迟持久化可以提高磁盘效率，如果在checkpoint之前mongo异常退出，再次启动可以根据journal恢复数据。</p>
<p>默认情况下，“journal”特性是开启的，特别在production环境中，我们没有理由来关闭它，当然也可以关闭journal，提高了性能，但单点mongo降低了数据安全性，如果有异常则丢失checkpoint之间的数据，副本集在所有节点同时退出的情况时有影响。</p>
<p>如果你希望数据尽可能的不丢失，可以考虑：</p>
<p>1）减小commitIntervalMs的值 </p>
<p>2）每个write指定“write concern”中指定“j”参数为true  </p>
<p>3）最佳手段就是采用“replica set”架构模式，通过数据备份方式解决，同时还需要在“write concern”中指定“w”选项，且保障级别不低于“majority”，最终我们需要在“写入性能”和“数据一致性”两个方面权衡，即CAP理论。</p>
<p><strong>至此mongodb的基础内容介绍得差不多，具体实践和高级技巧等工作项目中遇到了再深入研究，理论指导实践，在实<br>践中检验和调整升华理论，然后在下一次实践中表现得更加出色，理论和实践的螺旋式上升是不变的旋律</strong>。</p>
]]></content>
      
        <categories>
            
            <category> mongodb </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Theory </tag>
            
            <tag> Database </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mongodb]]></title>
      <url>/2018/01/18/Mongodb/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>Mongodb是时下流行的Nosql数据库，存储方式是文档式存储，并不是key-value形式。</p>
<p>参考<a href="http://blog.csdn.net/luonanqin/article/details/8497860" target="_blank" rel="external"><font color="#AAAAAA">CSDN的博客</font></a>，在本地使用三种方式实际搭建mongo集群:</p>
<p>1.replica set</p>
<p>2.sharding</p>
<p>3.master-slaver</p>
<p>万丈高楼平地起，无论业务多复杂，架构多庞大，归根到底还是数据库本身各种功能的应用，理解了数据库的设计原理，数据存储形式，掌握了基本的功能应用，集群构建，数据流动抽取备份，到了实际工作场景中无非数据量更大，应用形式多样化，架构更庞大而已。</p>
</blockquote>
<a id="more"></a>
<h1 id="replica-set"><a href="#replica-set" class="headerlink" title="replica set"></a><font color="#5CACEE">replica set</font></h1><p>副本集，简单来说就是集群当中包含了多份数据，保证主节点挂掉，备节点能继续提供服务，备节点与主节点的数据一致，如图</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516156461862.png" alt=""></p>
<p>Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点，主备节点存储数据，仲裁节点不存储数据，客户端连接主备，不连接仲裁节点。</p>
<p>默认设置下，主节点提供所有增删改查服务，备节点不提供服务。可以设置read preference modes，让备节点提供查询服务来分担主节点的压力，客户端进行的数据查询请求会自动转到备节点。</p>
<p>仲裁节点本身不存储数据，主要作用是决定哪个备节点在主节点挂掉后提升为主节点。多个备节点仍然只需要一个仲裁节点，本文中即使一个备节点也需要仲裁节点，如果没有，主节点挂了备节点还是备节点。</p>
<h2 id="集群设计"><a href="#集群设计" class="headerlink" title="集群设计"></a><font color="green">集群设计</font></h2><table>
<thead>
<tr>
<th>服务器</th>
<th>节点</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.3.7</td>
<td>主节点</td>
</tr>
<tr>
<td>192.168.3.8</td>
<td>备节点</td>
</tr>
<tr>
<td>192.168.3.9</td>
<td>仲裁节点</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>软件版本</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>mongodb-linux-x86_64-3.4.10</td>
<td><a href="https://pan.baidu.com/s/1qZ30PNQ" target="_blank" rel="external">下载地址</a></td>
</tr>
</tbody>
</table>
<h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a><font color="green">实验过程</font></h2><h3 id="解压到指定目录，创建数据文件夹"><a href="#解压到指定目录，创建数据文件夹" class="headerlink" title="解压到指定目录，创建数据文件夹"></a>解压到指定目录，创建数据文件夹</h3><pre><code>tar xvf mongodb-linux-x86_64-3.4.10.tgz -C /usr/local

cd /usr/local

mv mongodb-linux-x86_64-3.4.10/ mongodb

mkdir -p /usr/local/mongodb/data/master   
mkdir -p /usr/local/mongodb/data/slaver   
mkdir -p /usr/local/mongodb/data/arbiter    
三个目录分别对应主，备，仲裁节点
</code></pre><h3 id="建立配置文件-起mongo"><a href="#建立配置文件-起mongo" class="headerlink" title="建立配置文件,起mongo"></a>建立配置文件,起mongo</h3><blockquote>
<p>以下三个文件是三个节点的mongo启动参数文件，编辑好放在任何位置都可以，启动时按绝对路径指定即可</p>
</blockquote>
<pre><code>#master.conf  
dbpath=/usr/local/mongodb/data/master  
logpath=/usr/local/mongodb/log/master.log  
pidfilepath=/usr/local/mongodb/master.pid  
directoryperdb=true  
logappend=true  
replSet=testrs  
bind_ip=192.168.3.7  
port=27017
oplogSize=10000  
fork=true  
noprealloc=true

#slaver.conf
dbpath=/usr/local/mongodb/data/slaver  
logpath=/usr/local/mongodb/log/slaver.log  
pidfilepath=/usr/local/mongodb/slaver.pid  
directoryperdb=true  
logappend=true  
replSet=testrs  
bind_ip=192.168.3.8  
port=27017 
oplogSize=10000  
fork=true  
noprealloc=true 


#arbiter.conf  
dbpath=/usr/local/mongodb/data/arbiter  
logpath=/usr/local/mongodb/log/arbiter.log  
pidfilepath=/usr/local/mongodb/arbiter.pid  
directoryperdb=true  
logappend=true  
replSet=testrs  
bind_ip=1192.168.3.9  
port=27017
oplogSize=10000  
fork=true  
noprealloc=true  
</code></pre><blockquote>
<p><strong>参数解释</strong>：</p>
<p>dbpath：数据存放目录</p>
<p>logpath：日志存放路径</p>
<p>pidfilepath：进程文件，方便停止mongodb</p>
<p>directoryperdb：为每一个数据库按照数据库名建立文件夹存放</p>
<p>logappend：以追加的方式记录日志</p>
<p>replSet：replica set的名字</p>
<p>bind_ip：mongodb所绑定的ip地址</p>
<p>port：mongodb进程所使用的端口号，默认为27017</p>
<p>oplogSize：mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5%</p>
<p>fork：以后台方式运行进程</p>
<p>noprealloc：不预先分配存储</p>
</blockquote>
<pre><code>./mongod -f ../master.conf 
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516175089971.png" alt=""></p>
<p><code>./mongod -f ../slaver.conf</code><br><img src="http://p09u6sy9g.bkt.clouddn.com/1516175119466.png" alt=""></p>
<p><code>./mongod -f ../arbiter.conf</code><br><img src="http://p09u6sy9g.bkt.clouddn.com/1516175135042.png" alt=""></p>
<blockquote>
<p>原博客这里并没有提到需要手动创建log文件夹，经过若干次各个节点若干次启动失败各种原因排查，最终确定在我搭建的环境里需要手动创建log文件夹，但是原博文和推送我博文的朋友他们搭建过程貌似都不需要，不得解，待议。</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516174467395.png" alt=""></p>
<h3 id="配置主，备，仲裁节点"><a href="#配置主，备，仲裁节点" class="headerlink" title="配置主，备，仲裁节点"></a>配置主，备，仲裁节点</h3><pre><code>./mongo 192.168.3.7:27018   #ip和port是某个节点的地址  
&gt;use admin  
&gt;cfg={_id:&quot;testrs&quot;,members:[ {_id:0,host:&apos;192.168.3.7:27017&apos;,priority:2}, {_id:1,host:&apos;192.168.3.8:27017&apos;,priority:1},   
{_id:2,host:&apos;192.168.3.9:27017&apos;,arbiterOnly:true}] };  
&gt;rs.initiate(cfg) #使配置生效  
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516176794251.png" alt=""></p>
<blockquote>
<p>现在基本上已经完成了集群的所有搭建工作。</p>
</blockquote>
<pre><code>测试方案:
一个是往主节点插入数据，从备节点查询到之前插入的数据.

二是停掉主节点，让备节点变成主节点提供服务。

三是恢复主节点，备节点也能恢复其备的角色，而不是继续充当主的角色。二和三都可以通过rs.status()命令实时查看集群的变化
</code></pre><h1 id="sharding"><a href="#sharding" class="headerlink" title="sharding"></a><font color="#5CACEE">sharding</font></h1><p>和Replica Set类似，都需要一个仲裁节点，但是Sharding还需要配置节点和路由节点。就三种集群搭建方式来说，这种是最复杂的。部署图如下：<br><img src="http://p09u6sy9g.bkt.clouddn.com/1516182269464.png" alt=""></p>
<p>非常简单，懒得配了，看文档都能想到所有的具体操作和屏幕输出还有最后的结果，如果工作用到现搭就行了，有兴趣的自己去简介的原博客地址去撸一遍。</p>
<h1 id="master-slaver"><a href="#master-slaver" class="headerlink" title="master-slaver"></a><font color="#5CACEE">master-slaver</font></h1><blockquote>
<p>这个是最简答的集群搭建，严格来说不能算是集群，只能说是主备。并且官方已经不推荐这种方式，简单的介绍下，搭建方式相对简单。</p>
</blockquote>
<pre><code>./mongod --master --dbpath /data/masterdb/  #主节点  

./mongod --slave --source &lt;masterip:masterport&gt; --dbpath /data/slavedb/ 备节点  
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516180240698.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516180303967.png" alt=""></p>
<blockquote>
<p>只要在主节点和备节点上分别执行这两条命令，Master-Slaver就算搭建完成了。我没有试过主节点挂掉后备节点是否能变成主节点，不过既然官方已经不推荐了，了解即可。</p>
<p>三种集群搭建方式首选<code>Replica Set</code>，只有真的是大数据，Sharding才能显现威力，毕竟备节点同步数据是需要时间的。Sharding可以将多片数据集中到路由节点上进行一些对比，然后将数据返回给客户端，Replica Set的ips在数据达到1400w条时基本能达到1000左右，而Sharding在300w时已经下降到500ips，mongodb吃内存的问题，解决办法只能通过ulimit来控制内存使用量，但是如果控制不好的话，mongodb会挂掉</p>
</blockquote>
<h1 id="mongo数据库工作原理"><a href="#mongo数据库工作原理" class="headerlink" title="mongo数据库工作原理"></a><font color="#5CACEE">mongo数据库工作原理</font></h1><blockquote>
<p>MongoDB使用的是内存映射存储引擎，它会把磁盘IO操作转换成内存操作，如果是读操作，内存中的数据起到缓存的作用，如果是写操作，内存还可以把随机的写操作转换成顺序的写操作，总之可以大幅度提升性能。MongoDB并不干涉内存管理工作，而是把这些工作留给操作系统的虚拟缓存管理器去处理，这样的好处是简化了MongoDB的工作，但坏处是你没有方法很方便的控制MongoDB占多大内存，事实上MongoDB会占用所有能用的内存，所以最好不要把别的服务和MongoDB放一起。</p>
</blockquote>
<p>出于某些原因，你可能想释放掉MongoDB占用的内存，不过前面说了，内存管理工作是由虚拟内存管理器控制的，所以</p>
<pre><code>1.重启服务
2.调整内核参数drop_caches  systemctl vm.drop_caches=3
3.使用MongoDB内置的closeAllDatabases命令

可以通过mongo命令行来监控MongoDB的内存使用情况
db.serverStatus().mem
</code></pre><p>这篇博客简单介绍下怎么使用，具体技术细节服务库架构应用场景等我深入研究回来补上。</p>
]]></content>
      
        <categories>
            
            <category> Mongodb </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Database </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Leanote]]></title>
      <url>/2018/01/16/Leanote/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>Leanote 蚂蚁笔记是一款国产的在线网页版云笔记软件， 集知识管理、笔记、分享、博客功能于一身，界面简约但功能不简单！它支持多笔记本、标签分类、笔记共享、添加保存附件等，而且还提供了免打扰写作模式、支持图片尺寸调整、并且支持 Markdown 语法写作，最重要的是，它还能完美支持代码高亮显示！</p>
<p>该项目采用 Golang+MongoDB 开发，现已完全开源并能免费使用。普通用户可以直接使用 Leanote 提供的公共服务，也可以自行搭建属于自己或公司局域网内的私有云笔记平台。 而且，Leanote 可以让用户创建一个用户组，并将笔记共享到这个组里，所有组员都可以浏览、编辑笔记，可以非常方便地进行协作或知识共享。（题外话：团队内还可以通过 SeaFile 搭建私有的云存储配合使用）</p>
</blockquote>
<a id="more"></a>
<h1 id="搭建思路"><a href="#搭建思路" class="headerlink" title=" 搭建思路 "></a><font color="#5CACEE"> 搭建思路 </font></h1><pre><code>1.上传mongodb软件包到服务器，解压，起服务

2.上传leanote软件包到服务器，解压，修改配置文件，向mongodb导入lenote文件夹下的原始库表

4.起leanote服务
</code></pre><h1 id="软件包"><a href="#软件包" class="headerlink" title=" 软件包 "></a><font color="#5CACEE"> 软件包 </font></h1><table>
<thead>
<tr>
<th>软件包</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>mongodb-linux-x86_64-3.0.1</td>
<td><a href="https://pan.baidu.com/s/1dGGE0hV" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>leanote-linux-amd64-v2.6</td>
<td><a href="https://pan.baidu.com/s/1jJynuOQ" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>leanote-desktop</td>
<td><a href="https://pan.baidu.com/s/1sncACfb" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
</tbody>
</table>
<h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title=" 实验步骤 "></a><font color="#5CACEE"> 实验步骤 </font></h1><h2 id="1-上传，解压，创建数据文件夹，起服务"><a href="#1-上传，解压，创建数据文件夹，起服务" class="headerlink" title="1.上传，解压，创建数据文件夹，起服务"></a><font color="green">1.上传，解压，创建数据文件夹，起服务</font></h2><pre><code>$ tar xf mongodb-linux-x86_64-3.0.1.tgz -C /usr/local

$ mv mongodb-linux-x86_64-3.0.1/ mongodb

$ mkdir -p /usr/local/mongodb/data

$ /usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/data/ --bind_ip 127.0.0.1 &amp;&gt;&gt; /tmp/mongo.log &amp;  

$ kill -4 xxx        # xxx为mongo的进程号，安全关闭
</code></pre><h2 id="2-上传，解压，修改配置文件，导原始库表"><a href="#2-上传，解压，修改配置文件，导原始库表" class="headerlink" title="2.上传，解压，修改配置文件，导原始库表"></a><font color="green">2.上传，解压，修改配置文件，导原始库表</font></h2><pre><code>$ tar xf leanote-linux-amd64-v2.6.bin.tar.gz -C /usr/local/

$ vi /usr/local/leanote/conf/app.conf 

修改服务端口，加密字符串

$ /usr/local/mongodb/bin/mongorestore -h localhost -d leanote --dir /usr/local/leanote/mongodb_backup/leanote_install_data/
</code></pre><h2 id="3-起服务并验证可用"><a href="#3-起服务并验证可用" class="headerlink" title="3.起服务并验证可用"></a><font color="green">3.起服务并验证可用</font></h2><pre><code>$ cd /usr/local/leanote/bin

$ nohup ./run.sh &amp;   
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516067074310.png" alt=""></p>
<blockquote>
<p>进程正常</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516067113075.png" alt=""></p>
<blockquote>
<p>服务正常</p>
</blockquote>
<p><em>至此以私人服务器为server，<strong>仅供个人及好友使用</strong>的leanote搭建完成。</em></p>
<p><em>能在线编辑保存普通文件</em></p>
<p><em>能在线编辑保存markdown文件并发布为个人博客等</em></p>
<h1 id="效果演示"><a href="#效果演示" class="headerlink" title=" 效果演示 "></a><font color="#5CACEE"> 效果演示 </font></h1><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516067579674.png" alt=""></p>
<blockquote>
<p>这是leanote登陆页面，访问服务器的9000端口，如该服务器ip为192.168.x.x，访问”<a href="http://192.168.x.x:9000&quot;即可进入该页面。" target="_blank" rel="external">http://192.168.x.x:9000&quot;即可进入该页面。</a></p>
<p>因私人服务器性能有限，且非盈利自用，管理员已经关闭注册功能，使用该私人服务的唯一途径就是向管理者申请，通过后台单独添加用户</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516070707862.png" alt=""></p>
<blockquote>
<p>这是在线编辑页面，可以设置头像，访问别名，自定义很多参数，可以创建普通文本文件并保存，进行上传附件，插入图片，网页链接，版本管理等操作，类似有道云，为知等在线笔记</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/toblog.gif" alt=""></p>
<blockquote>
<p>可以将写好的markdown文件公布为博客，任何人都可以通过链接访问该博客，添加评论。</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516071739785.png" alt=""></p>
<blockquote>
<p>访问该网站就是对server服务器的9000端口发起访问请求，leanote将数据库的数据展示出来，用户编辑的普通文件和博客文件在保存后都会经过leanote的加密字符串运算加密后存放在数据库，本人对自己的文章具有最高权限，admin管理员具有后台添加删除用户并设置一些参数等权限，对普通用户的博客文章没有修改删除等权限。</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/desk.gif" alt=""></p>
<blockquote>
<p>有没有发现软件包有三个文件至此只用了两个，没错，第三个是leanote桌面版，下载解压就能用，不用安装，登陆的时候选择登陆自建服务，进去后可以像在线一样编辑文件，完成后保存，公布为博客，软件内即可访问自己的博客，而这所有的都是开源免费，如此干净高效，良心得我有点感动。</p>
</blockquote>
<h1 id="解锁更多姿势"><a href="#解锁更多姿势" class="headerlink" title=" 解锁更多姿势 "></a><font color="#5CACEE"> 解锁更多姿势 </font></h1><h2 id="1-数据库备份策略"><a href="#1-数据库备份策略" class="headerlink" title="1.数据库备份策略"></a><font color="green">1.数据库备份策略</font></h2><pre><code>备份
$ /usr/local/mongodb/bin/mongodump -h 127.0.0.1 -d leanote -o /~（备份集存放路径）


恢复
$ /usr/local/mongodb/bin/mongorestore -h 127.0.0.1 -d leanote --drop --dir ~/leanote （备份集所在路径）
</code></pre><blockquote>
<p>用linux系统自带的crontab定时执行备份脚本，实现每天三次备份，数据备份集可以保证即使服务挂了，甚至服务器挂了，被回收了，随时找个腾讯云或者阿里云的主机，分分钟重新搭建一套，导入数据后恢复服务，对普通用户来说除了期间无法使用之外，没有区别，所有数据都在。</p>
</blockquote>
<pre><code>$ crontab -l

0 6,14,22 * * * /usr/local/mongodb/backup/back.sh

$ more /usr/local/mongodb/backup/back.sh

#!/bin/sh

#该脚本通过crontab定时执行，实现每天6，14，22整点共三次备份mongo数据，保留两周内的备份集

#备份目录为BASEDIR，将带时间戳文件夹的备份集压缩，最后检测是否有14天前的文件夹，有则删除

BASEDIR=&quot;/usr/local/mongodb/backup&quot;

CURDIR=$BASEDIR/`date &quot;+%Y-%m-%d_%H.%M.%S&quot;`

/usr/local/mongodb/bin/mongodump -h 127.0.0.1 -d leanote -o $CURDIR

cd $CURDIR

tar -zcvf leanote.tar.gz leanote

rm -rf leanote/

find $BASEDIR -mtime +14 -exec rm -rf {} \;
</code></pre><h2 id="2-docker部署"><a href="#2-docker部署" class="headerlink" title="2.docker部署"></a><font color="green">2.docker部署</font></h2><p>1.制作docker镜像</p>
<p>docker是个很好用的工具，将系统，应用，程序制作成docker镜像，分发部署使用都会特别方便，这里是leanote的docker镜像，服务器有docker可以直接导入然后使用，没有需要先安装docker。导入制作好的<a href="https://pan.baidu.com/s/1slZC8TR" target="_blank" rel="external"><font color="#AAAAAA">docker镜像</font></a>并启动，这时所有前面配置过程的安装包，备份策略，配置文件更改都已经解决，使用效果一致。</p>
<p>2.一键部署使用<br>$ docker load -i leanote_2.6-image.tar.gz</p>
<p>$ docker history 69e799db2e66</p>
<p>$ docker run -tid –name leanote -p 80:80 –restart always -v /data/leanote:/data/  leanote:2.6</p>
<p>$ docker exec -ti cbc598f37d50 sh</p>
<p>$ tar xf leanote.tar.xz </p>
<p>$ mongorestore -h 127.0.0.1 -d leanote –drop –dir ./leanote</p>
<h2 id="3-使用技巧详细介绍"><a href="#3-使用技巧详细介绍" class="headerlink" title="3.使用技巧详细介绍"></a><font color="green">3.使用技巧详细介绍</font></h2><h3 id="1-普通用户傻瓜攻略"><a href="#1-普通用户傻瓜攻略" class="headerlink" title="1.普通用户傻瓜攻略"></a><font color="red">1.普通用户傻瓜攻略</font></h3><blockquote>
<p>普通用户不用管上述搭建过程，有兴趣的可以研究下，没兴趣知道怎么使用就足够了。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516067579674.png" alt=""><br>首先，访问。要在线写文章并保存以待后来回顾，写博客发布出去给别人看，得知道在哪里写，先访问我搭建的<a href="http://lovepanda.tk:9000/" target="_blank" rel="external"><font color="#AAAAAA">私人leanote</font></a>的网页；</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516092135404.png" alt=""></p>
<p>然后，登陆。你需要一个账号密码来登陆站点使用各种功能，我已经关闭了注册权限，新用户只能沟通后由我后台手动建立账号。因为服务器存储计算网络资源有限，这个服务也不是盈利性质，就是个使用方便小范围共享的利器，所以使用者那必须是有限制的。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/toblog.gif" alt=""></p>
<p>最后，编辑。登陆成功就可以为所欲为了，具体功能看本文中间段落<strong>效果演示</strong>。所有编写的文章和markdown（后缀为.md的博客文件）保存在我的服务器上，每天备份，保留两周的备份集，所以就可劲作吧。</p>
<p>最最后，可以写什么？</p>
<p>什么都可以写，在线写的文章和博客如果不发布，没有任何人可以看到，包括管理员，所有文章加密后保存在数据库；<br>可以发布出去，比如<a href="http://lovepanda.tk:9000/blog/post/alxinfff/Leanote" target="_blank" rel="external"><font color="#AAAAAA">这样</font></a>，发布的内容所有人都可以通过网络访问。</p>
<p>你可以写一些技术文档分类保存不发布，当作一个在线笔记存储，可以写一些游戏攻略经验发布出去装逼，可以写一些抒情的文章然后把链接给别人看（说真的，这个有点骚包，我绝逼干不出来这种事），基本功能就是这些，具体的骚操作自己开发，enjoy it！！！</p>
</blockquote>
<h3 id="2-深度用户高级攻略"><a href="#2-深度用户高级攻略" class="headerlink" title="2.深度用户高级攻略"></a><font color="red">2.深度用户高级攻略</font></h3>]]></content>
      
        <categories>
            
            <category> Software </category>
            
        </categories>
        
        
        <tags>
            
            <tag> service </tag>
            
            <tag> blog </tag>
            
            <tag> community </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HBase入门]]></title>
      <url>/2018/01/10/HBase%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>HBase – Hadoop Database，是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价 PC Server 上搭建起大规模结构化存储集群。</p>
<p>面向可扩展性的<strong>分布式数据库</strong>，如<code>hbase</code>，与面向高性能并发读写的<strong>key-value</strong>数据库，如<code>Redis</code>，面向海量数据访问的<strong>文档数据库</strong>，如<code>MongoDB</code>共同构成的应用场景，是用于解决在当前互联网发展阶段产生的巨量数据分布式处理，大量非结构化数据处理，各种社交平台日常生活中产生的的文本信息处理的重要解决方案。</p>
</blockquote>
<a id="more"></a>
<h1 id="Hbase是什么"><a href="#Hbase是什么" class="headerlink" title=" Hbase是什么 "></a><font color="#5CACEE"> Hbase是什么 </font></h1><p>HBase 是 Google Bigtable 的开源实现，类似 Google Bigtable 利用 GFS  作为其文件存储系统，HBase 利用 Hadoop HDFS 作为其文件存储系统；Google运行 MapReduce 来处理 Bigtable 中的海量数据，HBase 利用 Hadoop MapReduce 来处理 HBase 中的海量数据；Google Bigtable 利用 Chubby 作为协同服务，HBase 利用 ookeeper 作为对应。</p>
<p>HBase 是一个分布式的、面向列的开源数据库,是 Apache 的 Hadoop 项目的子项目。HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库,另一个不同是 HBase 基于列而不是基于行的模式。</p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1515029250857.png" alt=""></p>
<p>如图,HBase 位于结构化存储层，Hadoop HDFS 为 HBase  提供了高可靠性的底层存储支持，Hadoop MapReduc 为 HBase 提供了高性能的计算能力，Zookeeper 为 HBase 提供了稳定服务和 failover 机制。</p>
<p>Pig 和 Hive 还为 HBase 提供了高层语言支持，使得在 HBase 上进行数据统计处理变的非常简单。 Sqoop 则为 HBase 提供了方便的 RDBMS 数据导入功能，使得传统数据库数据向 HBase 中迁移变的非常方便。</p>
<p><strong>spark的构成</strong></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516938659693.png" alt=""></p>
<h1 id="如何访问Hbase"><a href="#如何访问Hbase" class="headerlink" title=" 如何访问Hbase "></a><font color="#5CACEE"> 如何访问Hbase </font></h1><pre><code>1. Native Java API，最常规和高效的访问方式，适合Hadoop MapReduce Job并行批处理HBase表数据
2. HBase Shell，HBase的命令行工具，最简单的接口，适合HBase管理使用
3. Thrift Gateway，利用Thrift序列化技术，支持C++，PHP，Python等多种语言，适合其他异构系统在线访问HBase表数据
4. REST Gateway，支持REST 风格的Http API访问HBase, 解除了语言限制
5. Pig，可以使用Pig Latin流式编程语言来操作HBase中的数据，和Hive类似，本质最终也是编译成MapReduce Job来处理HBase表数据，适合做数据统计
6. Hive，当前Hive的Release版本尚没有加入对HBase的支持，但在下一个版本Hive 0.7.0中将会支持HBase，可以使用类似SQL语言来访问HBase
</code></pre><h1 id="Hbase数据模型"><a href="#Hbase数据模型" class="headerlink" title=" Hbase数据模型 "></a><font color="#5CACEE"> Hbase数据模型 </font></h1><h2 id="HBase的特点"><a href="#HBase的特点" class="headerlink" title=" HBase的特点 "></a><font color="green"> HBase的特点 </font></h2><blockquote>
<ol>
<li>大：一个表可以有上亿行，上百万列。</li>
<li>面向列：面向列表（簇）的存储和权限控制，列（簇）独立检索。</li>
<li>稀疏：对于为空（NULL）的列，并不占用存储空间，因此，表可以设计的非常稀疏。</li>
<li>无模式：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以有截然不同的列。</li>
<li>数据多版本：每个单元中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳。</li>
<li>数据类型单一：HBase中的数据都是字符串，没有类型。</li>
</ol>
</blockquote>
<h2 id="Table-amp-Column-Family"><a href="#Table-amp-Column-Family" class="headerlink" title=" Table &amp; Column Family "></a><font color="green"> Table &amp; Column Family </font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515137523563.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1515031598634.png" alt=""></p>
<blockquote>
<p>Row Key: 行键，Table的主键，Table中的记录按照Row Key排序<br>访问 HBase table 中的行，只有三种方式：</p>
</blockquote>
<p>1)通过单个 Row Key 访问。</p>
<p>2)通过 Row Key 的 range 全表扫描。</p>
<p>3)Row Key 可以使任意字符串（最大长度是64KB，实际应用中长度一般为 10 ~ 100bytes），在HBase 内部，Row Key 保存为字节数组。</p>
<blockquote>
<p>Timestamp: 时间戳，每次数据操作对应的时间戳，可以看作是数据的version number</p>
<p>Column Family：列簇，Table在水平方向有一个或者多个Column Family组成，一个Column Family中可以由任意多个Column组成，即Column Family支持动态扩展，无需预先定义Column的数量以及类型，所有Column均以二进制格式存储，用户需要自行进行类型转换。</p>
<p>逻辑数据模型中空白cell在物理上是不存储的，因为根本没有必要存储，因此若一个请求为要获取t8时间的contents:html，他的结果就是空。相似的，若请求为获取t9时间的anchor:my.look.ca，结果也是空。但是，如果不指明时间，将会返回最新时间的行，每个最新的都会返回</p>
</blockquote>
<h2 id="Table-amp-Region"><a href="#Table-amp-Region" class="headerlink" title=" Table &amp; Region "></a><font color="green"> Table &amp; Region </font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515031712437.png" alt=""></p>
<blockquote>
<p>当Table随着记录数不断增加而变大后，会逐渐分裂成多份splits，成为regions，一个region由[startkey,endkey)表示，不同的region会被Master分配给相应的RegionServer进行管理</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1515031843096.png" alt=""></p>
<blockquote>
<p>HBase中有两张特殊的Table，-ROOT-和.META.</p>
<p>.META.：记录了用户表的Region信息，.META.可以有多个regoin</p>
<p>-ROOT-：记录了.META.表的Region信息，-ROOT-只有一个region</p>
<p>Zookeeper中记录了-ROOT-表的location</p>
</blockquote>
<h2 id="MapReduce-on-HBase"><a href="#MapReduce-on-HBase" class="headerlink" title=" MapReduce on HBase "></a><font color="green"> MapReduce on HBase </font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515032000264.png" alt=""></p>
<blockquote>
<p>在HBase系统上运行批处理运算，最方便和实用的模型依然是MapReduce，如图所示，HBase Table和Region的关系，比较类似HDFS File和Block的关系，HBase提供了配套的TableInputFormat和TableOutputFormat API，可以方便的将HBase Table作为Hadoop MapReduce的Source和Sink，对于MapReduce Job应用开发人员来说，基本不需要关注HBase系统自身的细节。</p>
</blockquote>
<h1 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title=" HBase系统架构 "></a><font color="#5CACEE"> HBase系统架构 </font></h1><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515032454254.png" alt=""></p>
<h2 id="Client"><a href="#Client" class="headerlink" title=" Client "></a><font color="green"> Client </font></h2><blockquote>
<p>HBase Client使用HBase的RPC（Remote Procedure Call – 远程过程调用）机制与HMaster和HRegionServer进行通信，对于管理类操作，Client与HMaster进行RPC；对于数据读写类操作，Client与HRegionServer进行RPC</p>
</blockquote>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title=" Zookeeper "></a><font color="green"> Zookeeper </font></h2><blockquote>
<p>Zookeeper Quorum中除了存储了-ROOT-表的地址和HMaster的地址，HRegionServer也会把自己以Ephemeral方式注册到 Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的健康状态。此外，Zookeeper也避免了HMaster的 单点问题</p>
</blockquote>
<h2 id="HMaster"><a href="#HMaster" class="headerlink" title=" HMaster "></a><font color="green"> HMaster </font></h2><blockquote>
<p>HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行，HMaster在功能上主要负责Table和Region的管理工作：</p>
</blockquote>
<pre><code>1.管理用户对Table的增、删、改、查操作

2.管理HRegionServer的负载均衡，调整Region分布

3.在Region Split后，负责新Region的分配

4.在HRegionServer停机后，负责失效HRegionServer 上的Regions迁移
</code></pre><h2 id="HRegionServer"><a href="#HRegionServer" class="headerlink" title=" HRegionServer "></a><font color="green"> HRegionServer </font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515033447893.png" alt=""></p>
<blockquote>
<p>HRegionServer主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块。</p>
<p>如图，HRegionServer内部管理了一系列HRegion对象，每个HRegion对应了Table中的一个Region，HRegion中由多个HStore组成。每个HStore对应了Table中的一个Column Family的存储，可以看出每个Column Family其实就是一个集中的存储单元</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1515048287534.png" alt=""></p>
<blockquote>
<p>HStore存储是HBase存储的核心,由两部分组成，一部分是MemStore，一部分是StoreFiles，MemStore是 Sorted Memory Buffer，用户写入的数据首先会放入MemStore，当MemStore满了以后会Flush成一个StoreFile（底层实现是HFile）， 当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFiles合并成一个StoreFile，合并过程中会进 行版本合并和数据删除，因此可以看出HBase其实只有增加数据，所有的更新和删除操作都是在后续的compact过程中进行的，这使得用户的写操作只要 进入内存中就可以立即返回，保证了HBase I/O的高性能。当StoreFiles Compact后，会逐步形成越来越大的StoreFile，当单个StoreFile大小超过一定阈值后，会触发Split操作，同时把当前 Region Split成2个Region，父Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer 上，使得原先1个Region的压力得以分流到2个Region上。</p>
<p>在理解了上述HStore的基本原理后，还必须了解一下HLog的功能，因为上述的HStore在系统正常工作的前提下是没有问题的，但是在分布式 系统环境中，无法避免系统出错或者宕机，因此一旦HRegionServer意外退出，MemStore中的内存数据将会丢失，这就需要引入HLog了。 每个HRegionServer中都有一个HLog对象，HLog是一个实现Write Ahead Log的类，在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中（HLog文件格式见后续），HLog文件定期会滚动出新的，并 删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知 到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复。</p>
</blockquote>
<h2 id="HBase存储格式"><a href="#HBase存储格式" class="headerlink" title=" HBase存储格式 "></a><font color="green"> HBase存储格式 </font></h2><blockquote>
<p>HBase中的所有数据文件都存储在Hadoop HDFS文件系统上，主要包括上述提出的两种文件类型：</p>
</blockquote>
<pre><code>1.HFile， HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile

2.HLog File，HBase中WAL（Write Ahead Log） 的存储格式，物理上是Hadoop的Sequence File
</code></pre><h3 id="HFile"><a href="#HFile" class="headerlink" title=" HFile "></a><font color="red"> HFile </font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515048543469.png" alt=""></p>
<blockquote>
<p>如图HFile的存储格式，首先HFile是不定长的，长度固定的只有其中两块:Trailer和Fileinfo。</p>
</blockquote>
<pre><code>Trailer中有指针指向其他数据块的起始点；
Fileinfo则记录了文件的部分meta信息，如AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY等;
Data Index和Meta Index块记录了每个Data块和Meta块的起始点。
</code></pre><blockquote>
<p>Data Block是HBase I/O的基本单元，为了提高效率，HRegionServer中有基于LRU的Block Cache机制。每个Data块的大小可以在创建一个Table的时候通过参数指定，大号的Block有利于顺序Scan，小号Block利于随机查询。 每个Data块除了开头的Magic以外就是一个个KeyValue对拼接而成, Magic内容就是一些随机数字，目的是防止数据损坏。后面会详细介绍每个KeyValue对的内部构造。</p>
</blockquote>
<pre><code>LRU:Least Recently Used ,内存管理的一种页面置换算法，对于在内存中但又不用的数据块（内存块）叫做LRU，操作系统会根据哪些数据属于LRU而将其移出内存而腾出空间来加载另外的数据。
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515049020714.png" alt=""></p>
<blockquote>
<p>HFile里面的每个KeyValue对就是一个简单的byte数组。但是这个byte数组里面包含了很多项，并且有固定的结构。具体结构如图:开始时两个固定长度的数值，分别表示key的长度和value的长度，紧接着是key，开始是固定长度的数值，表示rowkey的长度，紧接着是rowkey，然后是固定长度的数值，表示Family的长度，然后是Family，接着是Qualifier，然后是两个固定长度的数值，表示Time Stamp和Key Type（Put/Delete）。Value部分没有这么复杂的结构，就是纯粹的二进制数据。</p>
</blockquote>
<h3 id="HLogFile"><a href="#HLogFile" class="headerlink" title=" HLogFile "></a><font color="red"> HLogFile </font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1515063082942.png" alt=""></p>
<blockquote>
<p>如图是HLog文件的结构，其实HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。</p>
<p>HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue</p>
</blockquote>
<h1 id="HBase的高并发和实时处理数据"><a href="#HBase的高并发和实时处理数据" class="headerlink" title="HBase的高并发和实时处理数据"></a><font color="#5CACEE">HBase的高并发和实时处理数据</font></h1><blockquote>
<p>Hadoop是一个高容错、高延时的分布式文件系统和高并发的批处理系统，不适用于提供实时计算；HBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证其高容错性。</p>
<p>在生产环境中，HBase是如何基于hadoop提供实时性呢？</p>
<p> HBase上的数据是以StoreFile(HFile)二进制流的形式存储在HDFS上block块儿中；但是HDFS并不知道的HBase存的是什么，它只把存储文件视为二进制文件，也就是说，HBase的存储数据对于HDFS文件系统是透明的。</p>
<p> 从根本上说，HBase能提供实时计算服务主要原因是由其架构和底层的数据结构决定的，即由LSM-Tree + HTable(region分区) + Cache决定——客户端可以直接定位到要查数据所在的HRegion server服务器，然后直接在服务器的一个region上查找要匹配的数据，并且这些数据部分是经过cache缓存的。</p>
<p> 具体数据访问流程如下：</p>
<pre><code>1. Client会通过内部缓存的相关的-ROOT-中的信息和.META.中的信息直接连接与请求数据匹配的HRegion server；
2. 然后直接定位到该服务器上与客户请求对应的Region，客户请求首先会查询该Region在内存中的缓存——Memstore(Memstore是一个按key排序的树形结构的缓冲区)；
3. 如果在Memstore中查到结果则直接将结果返回给Client；
4. 在Memstore中没有查到匹配的数据，接下来会读已持久化的StoreFile文件中的数据，StoreFile也是按 key排序的树形结构的文件——并且是特别为范围查询或block查询优化过的，HBase读取磁盘文件是按其基本I/O单元(即 HBase Block)读数据的。
</code></pre></blockquote>
<p>hbase的具体配置使用跟hadoop，spark有密切关系，后面会有专门的博客来介绍openstack和hadoop，包括原理和配置，那里面会包含hbase的安装配置使用方法，这个坑交给后面的文章来填，就这么愉快得决定了！</p>
]]></content>
      
        <categories>
            
            <category> HBase </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Database </tag>
            
            <tag> Original </tag>
            
            <tag> Part-transported </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Google三大论文]]></title>
      <url>/2018/01/03/Google%E4%B8%89%E5%A4%A7%E8%AE%BA%E6%96%87/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>Google File System、MapReuce以及Bigtable三驾马车可以说是大数据算法的起源，虽然Google没有公布这三个产品的源码，但是他发布了这三个产品的详细设计论文，奠定了风靡全球的大数据算法的基础！</p>
</blockquote>
<table>
<thead>
<tr>
<th>软件</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google云计算三大论文英文版</td>
<td><a href="https://pan.baidu.com/s/1dFOyXOX" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Google-File-System中文版</td>
<td><a href="https://pan.baidu.com/s/1eShdCKa" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Google-MapReduce中文版</td>
<td><a href="https://pan.baidu.com/s/1jIOoRaA" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Google-Bigtable中文版</td>
<td><a href="https://pan.baidu.com/s/1geX8jLL" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
</tbody>
</table>
<a id="more"></a>
<h2 id="那些年google发过的论文"><a href="#那些年google发过的论文" class="headerlink" title=" 那些年google发过的论文 "></a><font color="green"> 那些年google发过的论文 </font></h2><blockquote>
<p>1.按时间算第一篇的论文应该2003年公布的<strong> Google File System</strong>，这是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。文件被分割成很多块，使用冗余的方式储存于商用机器集群上(基本上Google每篇论文都是关于“商用机型”)。</p>
<p>2.2004年发布的的<strong> MapReduce</strong>现在基本上可以代表大数据。主要思想是将任务分解然后在多台处理能力较弱的计算节点中同时处理，将结果合并从而完成大数据处理，传说中Google使用它计算他们的搜索索引。Mikio L. Braun(柏林工业大学机器学习学博士后，TWIMPACT联合创始人兼首席数据科学家)认为其工作模式应该是：Google把所有抓取的页面都放置于他们的集群上，并且每天都使用MapReduce来重算。</p>
<p>3.<strong>Bigtable</strong>发布于2006年，启发了无数的NoSQL数据库，比如：Cassandra、HBase等等。Cassandra架构中有一半是模仿Bigtable，包括了数据模型、SSTables以及提前写日志（另一半是模仿Amazon的Dynamo数据库，使用点对点集群模式）。</p>
<p>Google并没有止步于MapReduce，事实上，随着Internet的指数增长，从零开始重算所有搜索索引变得不切实际,他们在MapReduce不适用的地方开发新方法,对于大数据领域来说这是个福音。MapReduce不是万能的。当然，你可以更深入一步，比如说将磁盘数据移入内存，然而同样还存在一些任务的内部结构并不是MapReduce可以扩展的。</p>
<p>2010年发表的 <strong>Percolator</strong>的论文中，Google展示了其网络搜索是如何保持着与时俱进。Percolator建立于已存类似Bigtable的技术，但是加入了事务以及行和表上的锁和表变化的通知。这些通知之后会被用于触发不同阶段的计算。通过这样的方式，个体的更新就可以“渗透”整个数据库。</p>
<p>在2010年，Google还公布了 <strong>Dremel</strong>论文。一个为结构化数据设计，并拥有类SQL语言的交互式数据库。然而取代SQL数据库使用字段填补的表格，Dremel中使用的是类JSON格式数据（更准确的说，使用Google Protocol buffer格式，这将加强对允许字段的限制）。内部，数据被使用特殊格式储存，可以让数据扫描工作来的更高效。查询被送往服务器，而优秀的格式可以最大性能的输出结果</p>
<p>Google还需要挖掘图数据，比如在线社交网络的社交图谱；所以他们开发了 <strong>Pregel</strong>，并在2010年公布其论文。论文陈述了许多算法的实现，比如Google的PageRank、最短路径、二分图匹配等。Mikio L. Braun认为，对比MapReduce或SPF，Pregel需要更多实现的再思考。</p>
<p>Google在2009年提出了Spanner远景计划，并在2012年对外公布<strong>Spanner–全球分布式数据库</strong>论文。Spanner的公布可以说是Google向大数据技术中添的又一把火，Spanner具有高扩展性、多版本、全球级分布以及同步复制等特性，跨数据中心的高扩展性及全球分布会对一致性保障提出苛刻的需求,读写的外部一致性和基于时间戳的全局读一致性。为了保障这一点，Google引入了TrueTime API。TureTime API可以同步全球的时间，拥有一个TT.now（）的方法，将获得一个绝对时间，同时还能得到时间误差。为了保证万无一失，TrueTime API具有GPS和原子钟双保险。也只有这样的机制才能让全球范围内的并发处理得到保障。</p>
<p>在Google思路以及论文的启发下，同样涌现出一些开源项目，比如：Apache Drill、Apache Giraph、斯坦福GPS等等。</p>
<p>Google近年来每篇论文都有着深远的影响，同时大数据领域内有很多人必然在翘首以盼Google的下一篇论文。</p>
</blockquote>
<h2 id="Google-File-System-2003年"><a href="#Google-File-System-2003年" class="headerlink" title=" Google-File-System(2003年) "></a><font color="green"> Google-File-System(2003年) </font></h2><pre><code>文件被分割成很多块，使用冗余的方式储存于商用机器集群上
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514950151670.png" alt=""></p>
<h2 id="Google-MapReduce-2004年"><a href="#Google-MapReduce-2004年" class="headerlink" title=" Google-MapReduce (2004年)"></a><font color="green"> Google-MapReduce (2004年)</font></h2><pre><code>Mapreduce是针对分布式并行计算的一套编程模型
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514950324076.png" alt=""><br><img src="http://p09u6sy9g.bkt.clouddn.com/1514950356709.png" alt=""></p>
<h2 id="Google-Bigtable-2006年"><a href="#Google-Bigtable-2006年" class="headerlink" title=" Google-Bigtable(2006年)"></a><font color="green"> Google-Bigtable(2006年)</font></h2><pre><code>Bigtable发布于2006年，启发了无数的NoSQL数据库，比如：Cassandra、HBase等等
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514950769173.png" alt=""></p>
<pre><code>为了管理巨大的Table，把Table根据行分割，这些分割后的数据统称为：Tablets。每个Tablets大概有 100-200 MB，每个机器存储100个左右的 Tablets。底层的架构是：GFS。

由于GFS是一种分布式的文件系统，采用Tablets的机制后，可以获得很好的负载均衡。比如：可以把经常响应的表移动到其他空闲机器上，然后快速重建。
</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title=" 总结 "></a><font color="green"> 总结 </font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514950224224.png" alt=""></p>
<p><strong><em>MapReduce 和 BigTable都是以GFS为基础，三大基础核心技术构建出了完整的分布式运算架构。</em></strong></p>
<p>大数据的出现是互联网技术发展的<strong>大势所趋</strong>，随着越来越多的智能化数字化应用，社交媒体信息爆炸，超级大公司的业务数据不断膨胀，需要从海量数据中挖掘发现有价值的信息来进行商务决策，企业管理，产品调整，支撑各种互联网＋的公司，传统的高性能服务器加oracle等结构化数据库方案已经不足以满足需求。</p>
<p>谷歌本身就是一个体量巨大的全球性科技公司，旗下youtube，twitch，twitter，搜索业务，承载着互联网数据总量相当比重的<strong>处理压力</strong>，主动或者被动都要面对这个问题，从无到有地建立了一套技术体系之后，没有依靠技术垄断获取更大的利益，而是<strong>拿出了一整套解决方案的理论基础</strong>，可以说当前的这些分布式系统，框架，非结构化数据库，大部分都基于此，谷歌为互联网进入下个时代做出了极大的贡献，再次膜拜。</p>
<p>这是基于当前可观测事实的合理推测，事实上谷歌作为资本控制下的科技公司，做出这种大公无私的事可能性有但很小，大概率有自己的<strong>目的</strong>在里面，比如已经有了其他的解决方案，或许是另一个技术方向，用这些论文误导业界的发展方向，结果发现业界依然如火如荼┑(￣Д ￣)┍；比如是技术上又有了突破，把淘汰下来的技术拿出去给你们这些战五渣用(╯‵□′)╯︵┻━┻;又或者是有什么别的考量，遇上了瓶颈，把这些拿出来准备接受业界的反哺啦，跟某些团体有什么不可描述的py交易啦。这些都无所谓，论迹不论心，论心世上无完人，不管当时抱着什么目的，客观上确实极大地促进了大数据这个领域的发展，我宁愿相信谷歌出于公心出于科技界一员的责任感出于促进人类科技发展，主动自愿地发起了推动大数据领域前进的一系列行为，<em>科技宅天下第一！！！</em></p>
<p>最后说一句，估计有巨多的人都听说过谷歌的三篇传奇论文推进一个领域的故事，但是看过论文并仔细研究过的没多少，毕竟术业有专攻，该领域的从业人员限定就能划掉大部分人，领域内分工不同，也不是人人都需要看这些，又划掉一部分，比如我就没看过，写这篇博客是因为最近又开始玩hbase和mongo，查资料越查越深，决定单独把这三篇奠基性的论文拿出来过一遍，顺便mark一下。</p>
<p>最最后说一句，论文是最为精确信息量最大的，但这种专业度极高的文献看起来超级麻烦，所以我推荐b站的一个教学视频<a href="https://www.bilibili.com/video/av9787020/" target="_blank" rel="external"><font color="#AAAAAA">【大数据系统基础】.MOOC.清华大学</font></a>，可以说把GFS和MapReduce讲的相当透彻。</p>
<blockquote>
<p>PS:b站超良心的，up主把视频搬过来排版调好放在那没有广告免费观看，还可以选择2倍速，资源贼多，真真的“我在b站看纪录片”。</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1514959732808.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1514959759871.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> Bigdata </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Theory </tag>
            
            <tag> Paper </tag>
            
            <tag> Google </tag>
            
            <tag> Transported </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[安装配置]]></title>
      <url>/2018/01/02/Oracle%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>Oralce体系结构主要可以分为三个部分，对其分别进行深入理解可以很好得帮助理解oracle软件的运行和结构</p>
<ul>
<li>内存结构</li>
<li>进程结构</li>
<li>物理存储结构</li>
</ul>
</blockquote>
<a id="more"></a>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
<h2 id="一级目录"><a href="#一级目录" class="headerlink" title="一级目录"></a><font color="green">一级目录</font></h2><p>###<font color="red">二级目录</font>###</p>
<h4 id="三级目录"><a href="#三级目录" class="headerlink" title="三级目录"></a>三级目录</h4>]]></content>
      
        <categories>
            
            <category> Oracle </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Database </tag>
            
            <tag> Original </tag>
            
            <tag> Part-transported </tag>
            
            <tag> Operate </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[oracle大纲]]></title>
      <url>/2017/12/29/Oracle%E5%A4%A7%E7%BA%B2/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h1><blockquote>
<p>Oracle Database，又名Oracle RDBMS，或简称Oracle。是甲骨文公司的一款关系数据库管理系统。它是在数据库领域一直处于领先地位的产品。可以说Oracle数据库系统是目前世界上流行的关系数据库管理系统，系统可移植性好、使用方便、功能强，适用于各类大、中、小、微机环境。它是一种高效率、可靠性好的 适应高吞吐量的数据库解决方案。</p>
</blockquote>
<a id="more"></a>
<h1 id="oracle的起源"><a href="#oracle的起源" class="headerlink" title="oracle的起源"></a><font color="#5CACEE">oracle的起源</font></h1><p>oracle是<a href="https://baike.baidu.com/item/%E7%94%B2%E9%AA%A8%E6%96%87%E5%85%AC%E5%8F%B8/430115?fr=aladdin" target="_blank" rel="external"><font color="#AAAAAA">甲骨文公司</font></a>的拳头产品，是一个功能完善，商业应用程度极高的关系型数据库软件，是计算机行业发展的阶段性产物。</p>
<h1 id="数据库是什么"><a href="#数据库是什么" class="headerlink" title="数据库是什么"></a><font color="#5CACEE">数据库是什么</font></h1><p>数据库是按照数据结构组织，存储和管理数据的仓库，可视为电子化的文件柜，用户可以对文件中的数据进行新增、截取、更新、删除等操作。</p>
<p>它将数据以一定方式储存在一起、能为多个用户共享、具有尽可能小的冗余度，是与应用程序彼此独立的数据集合。</p>
<h2 id="数据库中数据的存储形式"><a href="#数据库中数据的存储形式" class="headerlink" title="数据库中数据的存储形式"></a><font color="#DDA0DD">数据库中数据的存储形式</font></h2><p>数据模型是数据库中数据的存储方式，是数据库系统的基础</p>
<p><strong>数据模型</strong>经历了：</p>
<blockquote>
<p>1.层次模型：层次模型发展最早，它以树结构为基本结构，典型代表是IMS模型。由于多数实际问题中数据间关系不简单地是树型结构，层次型数据模型渐被淘汰。</p>
<p>2.网状模型：网状数据模型通过网状结构表示数据间联系，开发较早且有一定优点，目前使用仍较多，典型代表是 DBTG模型。</p>
<p>3.关系型：关系模型开发较晚，它是通过满足一定条件的二维表格来表示实体集合以及数据间联系的一种模型，具有坚实的数学基础与理论基础，使用灵活方便，适应面广，发展十分迅速</p>
<p>4.非关系型 ： NoSQL( Not Only SQL )，用于指代那些非关系型的，分布式的，且一般不保证遵循ACID原则的数据存储系统。</p>
</blockquote>
<p><strong>关系型数据库</strong>是指采用了关系模型来组织数据的数据库，如<code>SQLite,Oracle,Mysql,SQLserver</code>，最大特点就是事务的一致性（ACID），简单来说，关系模型指的就是二维表格模型，关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。</p>
<blockquote>
<p>优点:</p>
<p>1、容易理解：二维表结构是非常贴近逻辑世界一个概念，关系模型相对网状、层次等其他模型来说更容易理解；</p>
<p>2、使用方便：通用的SQL语言使得操作关系型数据库非常方便；</p>
<p>3、易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率；</p>
<p>4、支持SQL，可用于复杂的查询。</p>
<p>缺点:</p>
<p>1、为了维护一致性所付出的巨大代价就是其读写性能比较差；</p>
<p>2、固定的表结构；</p>
<p>3、高并发读写需求；</p>
<p>4、海量数据的高效率读写；</p>
</blockquote>
<p><strong>非关系型数据库</strong>提出了另一种理念，随之产生的面向高性能并发读写的<strong>key-value</strong>数据库，如<code>Redis,Tokyo Cabinet,Flare</code> ，面向海量数据访问的<strong>面向文档数据库</strong>，如<code>MongoDB以及CouchDB</code>，面向可扩展性的<strong>分布式数据库</strong>,如<code>hadoop的hbase</code>，用于解决在当前互联网发展阶段产生的巨量数据分布式处理，大量非结构化数据处理，各种社交平台日常生活中产生的的文本信息处理。</p>
<blockquote>
<p>优点：</p>
<p>1）成本：nosql数据库简单易部署，基本都是开源软件，不需要像使用oracle那样花费大量成本购买使用，相比关系型数据库价格便宜。</p>
<p>2）查询速度：nosql数据库将数据存储于缓存之中，关系型数据库将数据存储在硬盘中，自然查询速度远不及nosql数据库。</p>
<p>3）存储数据的格式：nosql的存储格式是key,value形式、文档形式、图片形式等等，所以可以存储基础类型以及对象或者是集合等各种格式，而数据库则只支持基础类型。</p>
<p>4）扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。</p>
<p>缺点：</p>
<p>1）维护的工具和资料有限，因为nosql是属于新的技术，不能和关系型数据库10几年的技术同日而语。</p>
<p>2）不提供对sql的支持，如果不支持sql这样的工业标准，将产生一定用户的学习和使用成本。</p>
<p>3）不提供关系型数据库对事物的处理。</p>
</blockquote>
<h2 id="数据库技术的发展"><a href="#数据库技术的发展" class="headerlink" title="数据库技术的发展"></a><font color="#DDA0DD">数据库技术的发展</font></h2><p>未来不确定，但是可预测，基于事物发展的规律进行合理推测，更大的信息量带来的是更精确的预测结果。</p>
<p>数据库就是用来存储数据的一个容器，信息时代万物皆数据，当前科技的热门发展方向，智能汽车，无人机，机器学习，人工智能，物联网等等，都是基于对描述物质世界的巨量数据进行处理后得到期望的结果</p>
<blockquote>
<p>人工智能和深度学习不管是分类聚类算法，决策树还是神经网络，监督学习还是非监督学习，都要有经过预处理干净的数据集；物联网存在的基础就是存在于所有要监控和可监控的硬件中的嵌入式集成芯片，对这些芯片进行数据采集和操作来实现物联网控制一切的目的；智能汽车无人机这种基于数字技术和传感器的技术，最基础的技术很大部分都是对车辆行为数据集的学习和对行驶状态中数据的快速处理算法。</p>
</blockquote>
<p>数据是根本，对数据安全一致的存放管理和以合理形式进行组织应用的需求将会是永久的课题，不管将来信息科技如何发展，数据组织形式如何革新，数据库这一类对数据进行管理的软件永远有一席之地，而且必将是信息时代基石般的存在。</p>
<p>oracle作为关系型数据库领域登峰造极的产品，安全性稳定性可扩展性都已经高度成熟，从1977年IBM提出“关系数据库”的论文，埃里森以此做出oracle产品，并在之后的不断发展，到2013年甲骨文已经超越IBM,成为<strong>继MICORSOFT后全球第二大软件公司</strong>。oracle的各代产品在全世界各个行业，电信，电力，金融，政府及大量制造业扮演着很重要的角色，互联网总数据量的不断增长，现在的发展趋势是大数据处理，对非关系型，文本数据的处理需求使nosql类数据库和分布式处理框架越来越火，发展势头迅猛，然而在传统电信电力金融政府等领域，要处理的还是高度关系化，稳定性安全性需求极高的数据，oracle作为业界大佬，即使有了强力的挑战者，基本盘依然巨大，从业人员的需求短时间内也是不会衰退太多，而且作为如此成熟的一个产品，它的设计思路，工作方式都是值得深入学习，SQL和PL/SQL如此朴实通用的数据操作语言也是必须掌握。</p>
<p>从软件本身，从业，学习其他数据技术等各个角度来说，学习oracle都是一件拓宽眼界有益身心的事情。</p>
<h2 id="oracle知识谱系"><a href="#oracle知识谱系" class="headerlink" title="oracle知识谱系"></a><font color="#DDA0DD">oracle知识谱系</font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1513844572016.png" alt=""></p>
<p>上图知识谱系的内容基本能够覆盖诠释oracle的产品特性和使用，我会按照图中的思路来介绍oracle的相关技术，本文章是大纲，是oracle技能树的框架，后面我会每个分枝都用一篇博客来介绍。</p>
<p>(～￣(OO)￣)ブ，本来处于兴趣搭了个博客，又觉得空荡荡的写点东西好了，然后发现想到哪写到哪的写作方式效率太低，就大概规划了一下。</p>
<p>初步目标是由系列文章构成的oracle技能树，mysql技能树，mongodb技能树，python的一些相关内容，然后是研究生课程学的大数据相关内容，商务智能一篇，算法一片，数据仓库一篇，数据挖掘一篇，再加上自学的hadoop，spark这些，貌似不知不觉给自己挖了个巨坑啊（微笑挥手），加油填坑，跟妹子吹的牛跪着也要圆回来ORZ~~~</p>
<h3 id="体系结构（√）"><a href="#体系结构（√）" class="headerlink" title="体系结构（√）"></a><a href="https://uxtuo.github.io/2017/12/28/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/#more" target="_blank" rel="external"><font>体系结构（√）</font></a></h3><blockquote>
<p>内存结构</p>
<p>进程结构</p>
<p>物理存储结构</p>
</blockquote>
<h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a><font>安装配置</font></h3><h3 id="SQL和PL-SQL"><a href="#SQL和PL-SQL" class="headerlink" title="SQL和PL/SQL"></a><font>SQL和PL/SQL</font></h3><h3 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a><font>数据加载</font></h3><h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a><font>性能调优</font></h3><h3 id="数据迁移和备份恢复"><a href="#数据迁移和备份恢复" class="headerlink" title="数据迁移和备份恢复"></a><font>数据迁移和备份恢复</font></h3><h3 id="安全加固和故障处理"><a href="#安全加固和故障处理" class="headerlink" title="安全加固和故障处理"></a><font>安全加固和故障处理</font></h3>]]></content>
      
        <categories>
            
            <category> Oracle </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Framework </tag>
            
            <tag> Database </tag>
            
            <tag> Original </tag>
            
            <tag> Part-transported </tag>
            
            <tag> theory </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[体系结构]]></title>
      <url>/2017/12/28/Oracle%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h2><blockquote>
<p>Oralce体系结构主要可以分为三个部分，对其分别进行深入理解可以很好得帮助理解oracle软件的运行和结构</p>
<ul>
<li>内存结构</li>
<li>进程结构</li>
<li>物理存储结构</li>
</ul>
<p>Oracle服务器由数据库实例和数据库文件构成</p>
<p>数据库 = 数据文件 + 控制文件 + 日志文件</p>
<p>实例 = 内存池 + 后台进程</p>
<p>Oracle实例就是由一些内存区和后台进程构成的一个逻辑概念。<br>要访问数据库，先启动实例,分配内存区，然后启动后台进程</p>
</blockquote>
<a id="more"></a>
<h2 id="内存结构-SGA-PGA"><a href="#内存结构-SGA-PGA" class="headerlink" title="内存结构 SGA+PGA"></a><font color="green">内存结构 SGA+PGA</font></h2><p><img src="http://p09u6sy9g.bkt.clouddn.com/1513927427014.png" alt=""></p>
<h3 id="SGA-–-system-global-area"><a href="#SGA-–-system-global-area" class="headerlink" title="SGA – system global area"></a><font color="red">SGA – system global area</font></h3><pre><code>由所有服务进程和后台进程共享
</code></pre><h4 id="shared-pool"><a href="#shared-pool" class="headerlink" title="shared pool"></a>shared pool</h4><pre><code>缓存了各用户间可共享的各种结构
</code></pre><blockquote>
<p><br>数据字典，执行计划<br><br>数据块相关性高，版本转换产生bug的几率更大<br><br>SQL执行计划，硬解析和软解析<br><br>语法语句检查，软解析去shared pool调用缓存的执行计划，硬解析，分析统计信息，生成执行计划执行，得到数据，缓存到buffer cache，执行计划缓存到shared pool，发送给客户，网络问题产生的等待事件<br><br>当客户端进程，将SQL语句通过监听器发送到Oracle时, 会触发一个Server process生成，来对该客户进程服务。Server process得到SQL语句之后，对SQL语句进行Hash运算，然后根据Hash值到library cache中查找，如果存在，则直接将library cache中的缓存的执行计划拿来执行，最后将执行结果返回该客户端，这种SQL解析叫做软解析；如果不存在，则会对该SQL进行解析parse，然后执行，返回结果，这种SQL解析叫做硬解析。</p>
</blockquote>
<p>硬解析的步骤：</p>
<blockquote>
<p><br>1）对SQL语句进行语法检查，看是否有语法错误。如果存在语法错误，则退出解析过程；<br><br> 2）通过数据字典(row cache)，检查SQL语句中涉及的对象和列是否存在，检查SQL语句的用户是否对涉及到的对象是否有权限。<br><br>3）通过优化器创建一个最优的执行计划。这个过程会根据数据字典中的对象的统计信息，来计算多个执行计划的cost，从而得到一个最优的执行计划。这一步涉及到大量的数据运算，从而会消耗大量的CPU资源；(library cache最主要的目的就是通过软解析来减少这个步骤)；<br><br>4）将该游标所产生的执行计划，SQL文本等装载进library cache中的heap中。</p>
</blockquote>
<p>软解析：就是因为相同文本的SQL语句存在于library cache中，所以本次SQL语句的解析就可以去掉硬解析中的一个或多个步骤，从而节省大量的资源的耗费。<br><br>软软解析：就是不解析。</p>
<h4 id="buffer-cache"><a href="#buffer-cache" class="headerlink" title="buffer cache"></a>buffer cache</h4><pre><code>缓存了从磁盘上检索的数据块
</code></pre><p>灌数据     内存或者进程读数据，server process<br>排数据     dbwr<br>某个表经常使用，放在keep池中，防止冲出去</p>
<p>user I/O 等待事件，都是往buffer cache里灌的时候引起的，<br>system I/O 等待事件，都是往出排的时候</p>
<h4 id="redo-log-buffer"><a href="#redo-log-buffer" class="headerlink" title="redo log buffer"></a>redo log buffer</h4><pre><code>缓存了写到磁盘之前的重做信息
</code></pre><p>重做信息（用于实例恢复）在写入磁盘中存储的物理重做日志文件 之前，将缓存在此处<br>数据，undo的改变，会产生redo日志，写进logbuffer<br>触发事件后 lgwr 进程写出去，生成归档日志</p>
<h3 id="PGA-–-process-global-area"><a href="#PGA-–-process-global-area" class="headerlink" title="PGA – process global area"></a><font color="red">PGA – process global area</font></h3><pre><code>由每个服务进程、后台进程专有；每个进程都有一个PGA
</code></pre><blockquote>
<p>1.Private SQL area：包含绑定信息、运行时的内存结构。每个发出sql语句的会话，都有一个private SQL area（私有SQL区）</p>
<p>2.Session memory：为保存会话中的变量以及其他与会话相关的信息，而分配的内存区。</p>
</blockquote>
<p>pga不足的时候使用临时表空间</p>
<h3 id="SGA和PGA分配"><a href="#SGA和PGA分配" class="headerlink" title="SGA和PGA分配 "></a><font color="red">SGA和PGA分配 </font></h3><p>Oracle官方文档推荐:</p>
<pre><code>MEMORY_TARGET=物理内存 x 80%

MEMORY_MAX_SIZE=物理内存 x 80%

对于OLTP系统： 

SGA_TARGET=(物理内存 x 80%) x 80%

SGA_MAX_SIZE=(物理内存 x 80%) x 80%

PGA_AGGREGATE_TARGET=(物理内存 x 80%) x 20%

对于DSS系统：

SGA_TARGET=(物理内存 x 80%) x 50%

SGA_MAX_SIZE=(物理内存 x 80%) x 50%

PGA_AGGREGATE_TARGET=(物理内存 x 80%) x 50%
</code></pre><h2 id="进程结构"><a href="#进程结构" class="headerlink" title="进程结构"></a><font color="green">进程结构</font></h2><p>五个主要后台进程</p>
<pre><code>SQL&gt; select name,description from v$bgprocess where paddr&lt;&gt;&apos;00&apos;;
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514537708795.png" alt=""></p>
<h3 id="SMON-–-System-monitor-系统监控进程"><a href="#SMON-–-System-monitor-系统监控进程" class="headerlink" title="SMON – System monitor 系统监控进程 "></a><font color="red">SMON – System monitor 系统监控进程 </font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514538245662.png" alt=""></p>
<blockquote>
<p>SMON启动后会自动的用于在实例崩溃时进行数据库实例自动恢复。 </p>
<p>清除作废的排序临时段，回收整理碎片，合并空闲空间，释放临时段，维护闪回的时间点。 </p>
<p>在老数据库版本中，当我们大量删除表的时候，会观测到SMON进程很忙，直到把所有的碎片空间都整理完毕。</p>
</blockquote>
<h3 id="PMON-–-Process-monitor-进程监控"><a href="#PMON-–-Process-monitor-进程监控" class="headerlink" title="PMON – Process monitor 进程监控 "></a><font color="red">PMON – Process monitor 进程监控 </font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514538085023.png" alt=""></p>
<blockquote>
<p>PMON在后台进程执行失败后负责清理数据库缓存和闲置资源，是Oracle的自动维护机制。</p>
<ul>
<li>清除死进程</li>
<li>重新启动部分进程（如调度进程）</li>
<li>监听的自动注册</li>
<li>回滚事务</li>
<li>释放锁</li>
<li>释放其他资源</li>
</ul>
</blockquote>
<h3 id="DBWR-数据写进程"><a href="#DBWR-数据写进程" class="headerlink" title="DBWR 数据写进程"></a><font color="red">DBWR 数据写进程</font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514537996791.png" alt=""></p>
<blockquote>
<p>Server process连接Oracle后，通过数据库写进程(DBWn)将数据缓冲区中的“脏缓冲区”的数据块写入到存储结构(数据文件、磁盘文件)</p>
<p>只做一件事，将数据写到磁盘。就是将数据库的变化写入到数据文件。<br>该进程最多20 个，即使你有36 个CPU 也只能最多有20 个数据库写进程。<br>进程名称DBW0-DBW9 DBWa-DBWj </p>
</blockquote>
<h3 id="LGWR-日志写进程"><a href="#LGWR-日志写进程" class="headerlink" title="LGWR 日志写进程 "></a><font color="red">LGWR 日志写进程 </font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514538315144.png" alt=""></p>
<blockquote>
<p>主要用于记录数据库的改变和记录数据库被改变之前的原始状态，所以应当对其作多重备份，用于恢复和排错。</p>
<p>激活LGWR的情况：</p>
<ul>
<li>提交指令</li>
<li>日志缓冲区超过1/3</li>
<li>每三秒</li>
<li>每次DBWn执行之前</li>
</ul>
</blockquote>
<h3 id="CKPT-校验点进程"><a href="#CKPT-校验点进程" class="headerlink" title="CKPT  校验点进程"></a><font color="red">CKPT  校验点进程</font></h3><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514538043664.png" alt=""></p>
<blockquote>
<p>主要用户更新数据文件头，更新控制文件和触发DBWn数据库写进程。<br>Ckpt 进程会降低数据库性能，但是提高数据库崩溃时，自我恢复的性能。我们可以理解为阶段性的保存数据，一定的条件满足就触发，执行DBWn存盘操作。</p>
</blockquote>
<h2 id="物理结构"><a href="#物理结构" class="headerlink" title="物理结构"></a><font color="green">物理结构</font></h2><p>oracle数据库是个运行在操作系统上最终目的是存储和管理相关数据的软件</p>
<p>每一个Oracle数据库都是由三种类型的文件组成：数据文件（Data File）、日志文件（Log File）和控制文件（Control File）。数据库的文件为数据库信息提供真正的物理存储。</p>
<h3 id="一-控制文件"><a href="#一-控制文件" class="headerlink" title="一. 控制文件"></a><font color="red">一. 控制文件</font></h3><p>为二进制文件，初始化大小由CREATE DATABASE指定,可以使用RMAN备份</p>
<p>记录了当前数据库的结构信息,同时也包含数据文件及日志文件的信息以及相关的状态,归档信息等等</p>
<p>在参数文件中描述其位置，个数等等。通常采用分散放开，多路复用的原则。在mount阶段被读取，open阶段一直被使用</p>
<p>维护数据库一致性(数据库启动时会比较控制文件与联机日志文件中的ckpt,即起始scn号，如相等则正常启动，否则需要介质恢复)</p>
<p>一个控制文件只能属于一个数据库</p>
<p>控制文件的任意修改将写入到初始化参数中指定的所有控制文件中，读取时则仅读取第一个控制文件</p>
<p>控制文件只能连接一个数据库，控制文件的大小一般不要超过MB,最多为个，最少一个，互为镜像</p>
<p>控制文件中包含的内容</p>
<blockquote>
<p>数据库的名字、ID、创建的时间戳</p>
<p>表空间的名字</p>
<p>联机日志文件、数据文件的位置、个数、名字</p>
<p>联机日志的Sequence号码</p>
<p>检查点的信息</p>
<p>撤销段的开始或结束</p>
<p>归档信息</p>
<p>备份信息</p>
</blockquote>
<h4 id="一、何时创建新的控制文件"><a href="#一、何时创建新的控制文件" class="headerlink" title="一、何时创建新的控制文件"></a>一、何时创建新的控制文件</h4><blockquote>
<p>a、在控制文件发生永久性的损坏且之前未对控制文件进行备份</p>
<p>b、需要修改控制文件中的某些内容</p>
</blockquote>
<h4 id="二、多路复用控制文件"><a href="#二、多路复用控制文件" class="headerlink" title="二、多路复用控制文件"></a>二、多路复用控制文件</h4><blockquote>
<p>Oracle推荐最好将控制文件分布在不同的物理磁盘上。如果由于磁盘故障导致控制文件发生损坏，与之相关联的实例应被关闭。一旦磁盘被修复，可以通过其他磁盘上的控制文件恢复损坏的控制文件。待恢复完成后实例就可以重新启动，不需要进行介质恢复。<br>多路复用控制文件是如何进行工作的呢？<br>1、数据库启动时，仅读取control_file中第一个参数文件的信息<br>2、数据库打开时，将会向control_file中所有的控制文件更新信息<br>3、在数据库操作期间，如果任意一个控制文件不可用，实例将无法操作。</p>
</blockquote>
<h4 id="三、备份与恢复控制文件"><a href="#三、备份与恢复控制文件" class="headerlink" title="三、备份与恢复控制文件"></a>三、备份与恢复控制文件</h4><p>1、何时需要备份控制文件：</p>
<blockquote>
<p>a、添加、删除或重命名数据文件</p>
<p>b、添加、删除一个表空间或修改表空间的读写状态 //在添加，删除或重命名的前后都需要进行备份吗？文档没有说明，我认为应该这样。</p>
<p>c、添加、删除重做日志文件或组</p>
</blockquote>
<p>2、备份控制文件的方法如下：</p>
<blockquote>
<p>a、以二进制文件的形式备份控制文件：alter database backup controlfile to ‘/u02/backup’;</p>
<p>b、以SQL语句的形式备份控制文件便于以后可以重建：alter database backup controlfile to trace;该备份的存放位置可以通过查看alert告警日志获知。</p>
</blockquote>
<p>3、恢复控制文件的方法如下：</p>
<blockquote>
<p>a、假设control_file参数中的一个参数文件发生损坏，但是控制文件的存放目录仍然可以访问，这时可以：关闭数据库–&gt;cp控制文件另一副本覆盖损坏控制文件–startup</p>
<p>b、假设control_file参数中的一个参数文件发生发生介质损坏，这时可以：关闭数据库 –在新介质上恢复控制文件 –修改control_file参数 –startup<br>4、删除控制文件<br>    关闭数据库 –&gt; 修改control_file参数(删除对于信息) –&gt; startup，该系列操作不会删除操作系统上的物理文件，需要手动删除。</p>
</blockquote>
<h4 id="实验-rac-asm控制文件的多路复用"><a href="#实验-rac-asm控制文件的多路复用" class="headerlink" title="实验:rac+asm控制文件的多路复用"></a><strong>实验:rac+asm控制文件的多路复用</strong></h4><blockquote>
<p><code>SQLshow parameter control_files;</code></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1514449341804.png" alt=""></p>
<p><code>$ srvctl stop database -d CHAOS</code>  #关闭集群数据库</p>
<p><code>SQL&gt; startup nomount;</code> # 单节点启动到nomount状态</p>
<p>使用rman连接nomount状态的数据库并且备份控制文件到指定路径</p>
<p><code>$ rman target /</code></p>
<p><code>RMAN&gt; restore controlfile to &#39;+ORADATA/chaos/controlfile/current.260&#39; from &#39;+ORADATA/chaos/controlfile/current.260.958910433&#39;;</code></p>
<p>进入asmcmd，可以看到已经在目标路径生成备份</p>
<p><code>su - grid</code></p>
<p><code>$ export ORACLE_SID=+ASM</code></p>
<p><code>$ asmcmd</code></p>
<p><code>ASMCMD&gt; cd oradata/chaos/controlfile</code></p>
<p><code>ASMCMD&gt; ls</code></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1514452284051.png" alt=""></p>
<p><code>SQL&gt; alter system set control_files=&#39;+oradata/chaos/controlfile/current.270.963936137&#39;,&#39;+oradata/chaos/controlfile/current.260.958910433&#39; scope=spfile sid=&#39;*&#39;;   #自动生成了两个备份文件curren.260和current.270.963936137，用哪个都一样</code></p>
<p><code>$ srvctl start database -d CHAOS  #这个时候已经完成了对rac集群所有节点控制文件的多路复用</code></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1514452594076.png" alt=""></p>
</blockquote>
<h3 id="二-数据文件"><a href="#二-数据文件" class="headerlink" title="二.数据文件 "></a><font color="red">二.数据文件 </font></h3><p>每个数据库有一个或多个物理的数据文件。逻辑数据库结构（如表、索引等）的数据物理地存储在数据库的数据文件中，数据文件通常为*.dbf格式。<br>数据文件包含数据库中的实际数据，是数据库操作中数据的最终存储位置<br>数据文件有下列特征：</p>
<blockquote>
<p> 1、一个数据文件仅与一个数据库联系；</p>
<p> 2、一旦建立，数据文件只增不减；</p>
<p> 3、一个表空间（数据库存储的逻辑单位）由一个或多个数据文件组成。</p>
</blockquote>
<p> Oracle数据库在逻辑上是由多个表空间组成的，表空间在物理上包含一个或多个数据文件。而数据文件大小是块大小的整数倍；表空间中存储的对象叫段，比如数据段，索引段和回退段。段由区组成，区是磁盘分配的最小单位。段的增大是通过增加区的个数来实现的。每个区的大小是数据块大小的整数倍，区的大小可以不相同；数据块是数据库中的最小的I/O单位，同时也是内存数据缓冲区的单位，及数据文件存储空间单位。块的大小由参数DB_BLOCK_SIZE设置，其值应设置为操作系统块大小的整数倍。</p>
<p> 最后再来说一下Oracle的用户、表空间和数据文件之间的关系：<br>  一个用户可以使用一个或多个表空间，一个表空间也可以供多个用户使用。用户和表空间没有隶属关系，表空间是一个用来管理数据存储的逻辑概念，表空间只和数据文件存在关系，数据文件是物理的，一个表空间可以包含多个数据文件，而一个数据文件只能隶属一个表空间。</p>
<p>解释数据库、表空间、数据文件、表、数据的最好办法，就是<strong>想象一个装满东西的柜子，数据库其实就是柜子，柜中的抽屉是表空间，抽屉中的文件夹是数据文件，文件夹中的纸是表，写在纸上的信息就是数据</strong>。</p>
<h4 id="表空间：是一个或多个数据文件的逻辑集合"><a href="#表空间：是一个或多个数据文件的逻辑集合" class="headerlink" title="表空间：是一个或多个数据文件的逻辑集合"></a>表空间：是一个或多个数据文件的逻辑集合</h4><h4 id="表空间逻辑存储对象："><a href="#表空间逻辑存储对象：" class="headerlink" title="表空间逻辑存储对象："></a>表空间逻辑存储对象：</h4><p>   –永久段:如表与索引<br>   –临时段:如临时表数据与排序段<br>   –回滚段:用于事物回滚或闪回内存的撤销数据</p>
<h4 id="表空间分类："><a href="#表空间分类：" class="headerlink" title="表空间分类："></a>表空间分类：</h4><p>系统表空间(system、sysaux)，非系统表空间,一个表空间至少包含一个数据文件，一个数据文件只能属于一个表空间。</p>
<blockquote>
<p>   –SYSTEM :字典表空间，不能被损坏</p>
<p>   –UNDO   :dml,ddl把数据快照到此，数据提交即消失（用于恢复)</p>
<p>   –SYSAUX :10g 高并发系统繁忙时，会造成system争用，将工具放到SYSAUX,减轻system的压力，SYSAUX不影响系统（影响性能）</p>
<p>   –TEMP   :临时数据相关的内容</p>
<p>   –USERS  :10g  用户数据从system拨离出来</p>
</blockquote>
<p>逻辑结构是Oracle内部管理数据库中对象的方式<br>database数据库—&gt;tablespace表空间—&gt; segment段—&gt;extent区间—-&gt; block块</p>
<p>Schema: 用户—&gt;创建相关对象、表、视图、序列、函数、存储过程、包等</p>
<p>举例描述scott用户创建对象的组织方式,scott用户创建一张emp表，数据定义于system，数据逻辑存储于user表空间: 表段: 区间: 内存块/索引段: 区间: 内存块,user表空间<br>物理存储于user01.dbf数据文件，采用本地管理，包含头部信息，可用，已用等位图信息，buffer cache满或者commit之后dbwr进程将数据从内存写到物理文件中</p>
<pre><code>`SQL&gt; select username,default_tablespace,temporary_tablespace from dba_users where username=&apos;SCOTT&apos;;`
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514427149119.png" alt=""></p>
<pre><code>SQL&gt; select t1.name tbname,t2.name from v$tablespace t1,v$datafile t2 where t1.ts# = t2.ts#;#查看当前数据库所有表空间及其数据文件路径
</code></pre><blockquote>
<p><code>SQL&gt; select file_name,tablespace_name from dba_data_files;</code>  #  某人竟然嘲讽我，哼哼<br><img src="http://p09u6sy9g.bkt.clouddn.com/1514427174791.png" alt=""></p>
</blockquote>
<h4 id="表空间管理"><a href="#表空间管理" class="headerlink" title="表空间管理"></a>表空间管理</h4><p>创建表空间的条件</p>
<blockquote>
<p>1.具有create tablespace权限，dba，sysdba，sysoper拥有改权限，可授予</p>
<p>2.创建的是bigfile/smallfile，超过T级应考虑bigfile</p>
<p>3.新建的表空间的I/O，是否会导致磁盘I/O不够用</p>
<p>4.oracle需要具有创建表空间时指定datafile路径的写权限</p>
</blockquote>
<p> <code>SQL&gt; select PROPERTY_NAME,PROPERTY_VALUE from database_properties where PROPERTY_NAME like &#39;%TBS%&#39;;  #查看表空间创建缺省状态时bigfile还是smallfile</code></p>
<p> <code>SQL&gt; alter database set default bigfile/smallfile tablespace;  #修改创建表空间缺省为大/小文件状态</code></p>
<p>大表文件（bigfile)最大可以存放个T的容量。头文件的大小达到了G－－＞block,普通的头文件大小为M—-&gt;block。<br>好处：减少了数据文件的个数，管理方便，大的对象的存放得到了优化。减少了control文件的信息，控制文件定义了datafile的个数。<br>bigfile只能存在一个数据文件，所以要保证分配的的磁盘具有足够的空间。</p>
<pre><code>SQL&gt; create tablespace TBS1 datafile &apos;+ORADATA/chaos/datafile/tbs1.dbf&apos; size 100m;   #创建数据文件路径为 &apos;~tbs1.dbf&apos;的名为TBS1的表空间

SQL&gt; create temporary tablespace TMP1 tempfile &apos;+ORADATA/chaos/datafile/tmp1.dbf&apos; size 10m; 创建数据文件路径为 &apos;~tmp1.dbf&apos;的名为TBS2的临时表空间，临时表空间文件不能设置为只读，不能重命名数据文件，日志方式总是nologing，主要用途是在数据库进行排序运算，管理索引，访问视图等操作时提供临时的运算空间，当运算完成之后系统会自动清理，因为用途不同所以才有了默认表空间和临时表空间区分，实际上数据库都是有默认临时空间的，但实际应用中很难满足需求，所以才需要自己创建临时空间。

SQL&gt; alter database tempfile &apos;+ORADATA/chaos/tempfile/tmp1.dbf&apos; resize 15m; #重置大小

SQL&gt; alter database tempfile &apos;+ORADATA/chaos/tempfile/tmp1.dbf&apos; autoextend on next 10m maxsize 100m;#打开自动扩展

SQL&gt; alter tablespace tmp1 add tempfile &apos;+ORADATA/chaos/datafile/tmp2.dbf&apos; size 10m;   #给临时表空间增加临时文件，增加到表空间中的数据文件不能直接从表空间中删除，除非删掉整个表空间，增加数据文件将有助于均衡I/O

SQL&gt; alter database default temporary tablespace tmp1;   #设置tmp1为默认临时表空间，如果没有指定默认临时表空间，那么将使用system表空间作为排序区

SQL&gt; SELECT dbms_metadata.get_ddl(&apos;TABLESPACE&apos;,&apos;SYSTEM&apos;) FROM dual;  #查看创建表空间语句
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514427094493.png" alt=""></p>
<pre><code>SQL&gt; CREATE UNDO TABLESPACE tablespace_name DATAFILE &apos;+ORADATA/chaos/datafile/undotbs2.dbf&apos; size 10m;  #创建undo表空间

SQL&gt; ALTER SYSTEM SET UNDO_TABLESPACE=tablespace_name;   #修改默认undo表空间
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514427510106.png" alt=""></p>
<pre><code>SQL&gt; alter tablespace TABLESPACE_NAME rename to TBS2; # 表空间改名

undo表空间扩容，重置表空间大小，添加数据文件，自动扩展，跟临时表空间操作没有区别

SQL&gt; drop tablespace tbs2；  #删除表空间，注意，system，sysaux，user表空间强烈不建议删除，会崩，默认表空间和当前undo表空间无法删除
</code></pre><p>表空间的管理方式</p>
<pre><code>SQL&gt; select TABLESPACE_NAME,EXTENT_MANAGEMENT,BLOCK_SIZE,STATUS,CONTENTS,FORCE_LOGGING,BIGFILE from dba_tablespaces;
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514428149844.png" alt=""></p>
<p>字典管理:字典管理表空间-DMT，指oracle的表空间分配和回收是通过数据库中的数据字典表来记录和管理，用于管理的两个数据字典分别是 UET$（used extents)和FET$(freeextents),其工作方式是当建立一个新的段或者表空间时，oracle通过一系列SQL语句来完成这个工作，更新<br>上述两个字点的信息，在繁忙系统中会造成竞争和等待（另一个DMT会带来的问题是空间碎片）</p>
<p>本地管理:LMT的表空间数据文件头部加入了一个位图区域，在其中记录每个extent的使用状况，当extent被使用或者被释放，oracle会更新头部的记录来反映这个变化，不产生回滚信息，因为仅仅操作数据文件头部的几个数据块，不用操作数据字典，LMT比DMT要快，尤其是数据库繁忙的时候更明显</p>
<p>通过使用PL/SQL 完成表空间转换 </p>
<pre><code>exec dbms_space_admin.tablespace_migrate_to_local(&apos;USERS&apos;);
exec dbms_space_admin.tablespace_migrate_from_local(&apos;USERS&apos;);
</code></pre><h4 id="表空间的四种状态："><a href="#表空间的四种状态：" class="headerlink" title="表空间的四种状态："></a>表空间的四种状态：</h4><p>online</p>
<p>offline</p>
<p>read only</p>
<p>read write</p>
<p>一个表空间的正常状态是联机（online），有时需要将某表空间进行脱机，以进行数据库维护</p>
<p>如：在数据打开的状态下移动数据文件，恢复一个表空间或数据文件,执行表空间的脱机备份，在数据库正常工作情况下使数据库的某部分不可访问</p>
<pre><code>SQL&gt; alter tablespace tbs1 offline;

SQL&gt; alter tablespace tbs1 online;
</code></pre><p>read only状态不能执行DML语句，可以使用DDL，DQL语句</p>
<pre><code>SQL&gt; alter tablespace tbs1 read only;

SQL&gt; alter tablespace tbs1 read write;

system 必须online 必须read write

sysaux 可以offline 不能read only

undo 不能offline 不能read only

SQL&gt; select tablespace_name,file#,v.status,v.enabled from dba_data_files d,v$datafile v where d.file_id = v.file#;  #查看表空间的状态
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1514447367034.png" alt=""></p>
<p>表空间重定位</p>
<p>open且archive状态，先offline，移动数据文件位置，修改控制文件该数据文件路径，online</p>
<h4 id="表空间相关视图"><a href="#表空间相关视图" class="headerlink" title="表空间相关视图"></a><em>表空间相关视图</em></h4><pre><code>表空间数据字典视图:DBA_TABLESPACES
表空间动态性能视图:V$TABLESPACE
数据字典视图:DBA_DATA_FILES
动态性能视图:V$DATAFILE
数据字典视图:DBA_TEMP_FILES
动态性能视图:V$TEMPFILE
被段分配的区:DBA_EXTENTS
没有被段分配的区: DBA_FREE_SPACE
系统表空间默认设置:database_properties
</code></pre><h3 id="三-归档文件"><a href="#三-归档文件" class="headerlink" title=" 三.归档文件 "></a><font color="red"> 三.归档文件 </font></h3><p>在重做日志分成2部分，一个是在线重做日志文件，另外一个就是归档日志文件。在线重做日志大小毕竟是有限的，当都写满了的时候，就面临着2个选择，第一个就是把以前在线重做日志从头擦除开始继续写，第二种就是把以前的在线重做日志先进行备份，然后对被备份的日志擦除开始写新的在线Redo File。这种备份的在线重做日志就是归档日志。而数据库如果采用这种生成归档日志的模式的话，就是归档日志模式(ARCHIVELOG模式)，反之如果不生成归档日志，就是非归档日志模式(NOARCHIVELOG模式)。</p>
<p>归档日志(Archive Log)是非活动的重做日志备份.通过使用归档日志,可以保留所有重做历史记录,当数据库处于ARCHIVELOG模式并进行日志切换式,后台进程ARCH会将重做日志的内容保存到归档日志中.当数据库出现介质失败时,使用数据文件备份,归档日志和重做日志可以完全恢复数据库.</p>
<h4 id="实验-rac环境下修改归档模式"><a href="#实验-rac环境下修改归档模式" class="headerlink" title="实验: rac环境下修改归档模式"></a>实验: rac环境下修改归档模式</h4><p>rac环境的归档模式切换和单实例稍有不同，主要是共享存储所产生的差异，将rac数据库切换到非集群状态下，在一个实例上实施归档模式切换即可完成rac数据库归档模式转换问题，非切归与归切非为镜像操作，这里仅描述切成归档模式的具体操作</p>
<p>1.主要步骤</p>
<ul>
<li>备份spfile，防止参数修改失败导致数据库无法启动</li>
<li>修改集群参数cluster_database为false</li>
<li>关闭集群数据库</li>
<li>启动单实例到mount状态</li>
<li>修改该实例为归档模式（alter database archivelog/noarchivelog）</li>
<li>修改集群参数cluster_database为true</li>
<li>关闭单实例，启动集群数据库</li>
</ul>
<p>2.操作</p>
<pre><code>查看归档模式

SQL&gt; archive log list;

SQL&gt; select instance_name,host_name,status from gv$instance;

SQL&gt; show parameter cluster；

SQL&gt; create pfile=&apos;/u01/app/oracle/spfileback.ora&apos; from spfile;  #备份spfile

SQL&gt; alter system set cluster_database=false scope=spfile sid=&apos;*&apos;;  #修改为非集群数据库，该参数为静态参数，需要使用scope=spfile

退出sql命令行在linux命令行下面执行集群和单节点的起停操作

$ srvctl stop database -d CHAOS#停集群数据库

$ srvctl start instance -d CHAOS -i CHAOS1 -o mount   #起单个实例到mount状态

SQL&gt; select instance_name,status from v$instance;   #查看启动的单实例的数据库的状态，这个时候应该是mounted状态

SQL&gt; alter database archivelog;   #在mount状态下设置该单实例为归档模式

SQL&gt; alter system set cluster_database=true scope=spfile sid=&apos;*&apos;;   #修改为集群数据库

$ srvctl stop instance -d CHAOS -i CHAOS1#关闭当前操作的单实例数据库

$ srvctl start database -d CHAOS#起集群数据库
</code></pre><p>以上操作按顺序执行，已经在本机实验环境中实际操作验证，执行完最后的起集群操作之后双节点上数据库都处于open状态，并成功修改为归档模式。<br>双节点实验环境是这样，实际生产环境多节点操作也是同理，多节点rac修改归档模式笨办法就是挨个节点启动到mount状态并修改，好处是不影响其他节点的工作，缺点是工作量略大，并且得执行节点数*2的起停数据库操作，风险稍大。<br>这样修改集群状态，更改单实例归档模式，让其他节点自动同步的方式不管有多少节点都一次到位，并且只要操作一次集群的起停操作和一次单实例的起停操作，安全高效</p>
<p>一些归档文件的操作</p>
<pre><code>SQL&gt; alter system switch logfile; # 手工切归档

SQL&gt; select inst_id,name,thread#,sequence#,status from gv$archived_log;   #查看归档日志

SQL&gt; select * from v$log;#查看v$log视图里的归档文件信息

SQL&gt; alter system set log_archive_dest = &apos;/u01/app/oracle/arch1/&apos; scope = spfile;  #修改归档文件路径

SQL&gt; alter system set log_archive_duplex_dest = &apos;/u01/app/oracle/arch2&apos; scope = spfile;   #归档到本机且大于等于两个归档位置

SQL&gt; alter system set log_archive_format = &apos;arch_%t_%s_%r.arc&apos;;  #修改归档文件命名格式
</code></pre><h4 id="归档日志相关视图"><a href="#归档日志相关视图" class="headerlink" title="归档日志相关视图"></a><em>归档日志相关视图</em></h4><pre><code>v$archived_log  #从控制文件中获得归档的相关信息

v$archive_dest  #归档路径及状态

v$log_history   #控制文件中日志的历史信息

v$archive_processes #归档相关的后台进程信息
</code></pre><h2 id="rac起停操作"><a href="#rac起停操作" class="headerlink" title="rac起停操作"></a>rac起停操作</h2><h3 id="进程正常"><a href="#进程正常" class="headerlink" title="进程正常"></a>进程正常</h3><p>如图，双节点RAC进程正常，端口监听正常，可以对外提供服务<br><img src="http://p09u6sy9g.bkt.clouddn.com/1516161797321.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516161937018.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516161963701.png" alt=""></p>
<h3 id="停止HAS-High-Availability-Services"><a href="#停止HAS-High-Availability-Services" class="headerlink" title="停止HAS(High Availability Services)"></a>停止HAS(High Availability Services)</h3><p>必须以root用户操作，每个rac节点都得执行，在执行过程中vip会不断漂移到正常节点，直到所有节点服务都被关闭，执行完成后所有节点1521端口不再监听，所有相关进程全部清除，集群无法被访问</p>
<pre><code># cd /u01/app/11.2/grid/bin

# ./crsctl stop has -f
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516162462783.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516164898940.png" alt=""></p>
<h3 id="启动HAS"><a href="#启动HAS" class="headerlink" title="启动HAS"></a>启动HAS</h3><p>root在每个rac节点执行起has的命令，可以在单一节点启动集群数据库</p>
<pre><code># crsctl start has 

$ srvctl status database -d racdb   oracle用户
</code></pre><p><img src="http://p09u6sy9g.bkt.clouddn.com/1516165599493.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516165626017.png" alt=""></p>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1516165664331.png" alt=""></p>
<p>可以看到所有的rac相关进程都已经启动，可以通过sqlplus本地登陆，用开发工具访问vip也正常，这是一次完整的rac起停过程</p>
]]></content>
      
        <categories>
            
            <category> Oracle </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Theory </tag>
            
            <tag> Database </tag>
            
            <tag> Original </tag>
            
            <tag> Part-transported </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[搭建个人博客]]></title>
      <url>/2017/11/14/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h2><blockquote>
<p>  Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。看官档是个好习惯，<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="external"><font color="#AAAAAA">戳这里</font></a>跟着官方的文档走清晰明确又全面。</p>
<p><br>很久前搭建过一个基于wordpress的博客，然而那个时候并没有写东西的兴趣，完成了环境搭建之后确定博客可用，实验过程可复现就没再管理。</p>
<p><br>最近一直在看世界历史，越发感觉到生产关系和生产资料在人类文明史发展过程中的核心地位，可以清楚得看到历史的脉络跟生产力的发展之间的关系.</p>
<p><br>做个对社会有贡献的人真的不是一句套话。生产资料的占有者，生产关系中的生产者，社会财富的创造者,这些人才真的有机会去在社会变革的浪潮中大幅度改变既定的人生轨迹。</p>
<p><br>在信息时代，在下一次科技革命的前夕，在即将到来注定是数字化信息化的世界里，一切皆数据。数据就是新的生产资料，用数据去形成各种特定功能的产品，解决问题，就是新世界的生产关系，就如同石器时代会做石斧，铁器时代掌握了冶金技术，化石能源时代掌握了开采石油并加工成产品，核能时代掌握了可控核聚变技术一样，在数据时代中掌握了跟数据相关的姿势，从数据的收集和传递，存储，到在线分析，机器学习，人工智能、从数据支持的企业商务决策到各种炫酷到不行的网页设计，前端展示。就算站不到浪潮之巅，苟全性命于盛世绰绰有余。</p>
<p><br>这个博客第一是把我的学习状态和进度拿出来晒一晒，即使没人看，也是对我自己的一种鼓励（ps：万一有人看到了呢），现在处于大数据职业技能树生成阶段，既然走在正确的路上，用点手段督促自己走快点。再一个就是分享一些技术文档，刚从菜鸟阶段提升了一点，踩过的坑，做过的事都摆出来，看看能不能帮到一起前进的同道中人，也算是一种展现自己价值的方式。</p>
</blockquote>
<a id="more"></a>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a><font color="#5CACEE">思路</font></h2><blockquote>
<p>要搭建一个自己的博客，可以选择类似CSDN之类的网站，网站提供现成服务和模板，作者编辑内容后提交，网站审核发布。也可以在自己的服务器上用博客模板搭建服务，编辑内容后发布，游客通过访问服务器来访问作者的博客。我在某服务商那里常年租借VPS，所以选择自己搭建。<br> <br>搭建的时候可以选择<a href="https://baike.baidu.com/item/WordPress/450615?fr=aladdin" target="_blank" rel="external"><font color="#AAAAAA">wrodpress</font></a>，<a href="https://gohugo.io/" target="_blank" rel="external"><font color="#AAAAAA">hugo</font></a>，<a href="https://jekyllrb.com/" target="_blank" rel="external"><font color="#AAAAAA">jekyll</font></a>,<a href="https://hexo.io/zh-cn/" target="_blank" rel="external"><font color="#AAAAAA">hexo</font></a>等博客框架和生成静态网页的工具，这里选择使用的是hexo。<br><br>确定了要做什么和怎么做，之后的事情就简单了。用xshell或CRT终端连接VPS，部署服务，编辑内容，测试，发布，博客就算搭建完成。<br><br>搭建完成后得提供访问地址，总不能给别人一个IP和端口说“这是我的博客，跑在这个服务器这个端口上，欢迎访问”。一不专业，二不安全，建议申请域名进行<a href="https://baike.baidu.com/item/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/574285?fr=aladdin" target="_blank" rel="external"><font color="#AAAAAA">域名解析</font></a>，可以选择国内的域名，申请备案然后使用。笔者这里选择在<a href="http://www.freenom.com/zh/index.html?lang=zh" target="_blank" rel="external"><font color="#AAAAAA">freenom</font></a>申请一个免费域名并设置解析VPS，达到通过域名直接访问博客的目的，同时因为是境外的域名，所以不涉及到备案，可以直接访问。还可以通过更改配置文件，添加公钥等步骤将博客设置托管到github上，通过github提供的服务来访问博客，好处是所有的内容都会推送一份到github上，哪怕服务器挂了也算有个备份。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a><font color="#5CACEE">环境</font></h2></blockquote>
<table>
<thead>
<tr>
<th>软件</th>
<th>下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td> node.js</td>
<td><a href="https://nodejs.org/zh-cn/download/" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td> git</td>
<td><font color="#AAAAAA">yum安装即可</font></td>
</tr>
<tr>
<td> hexo</td>
<td><font color="#AAAAAA">npm安装即可</font></td>
</tr>
<tr>
<td> nginx</td>
<td><a href="http://nginx.org/download/nginx-1.13.6.tar.gz" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
</tbody>
</table>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a><font color="#5CACEE">步骤</font></h2><h3 id="一-安装"><a href="#一-安装" class="headerlink" title="一 安装 "></a><font color="#CDAA7D">一 安装 </font></h3><h4 id="1-安装node-js"><a href="#1-安装node-js" class="headerlink" title="1. 安装node.js"></a><font color="#CDAA7D">1. 安装node.js</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh node-8.4.0-el6.x86_64.rpm</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512702233333.png" alt="avatar"></p>
<h4 id="2-安装git"><a href="#2-安装git" class="headerlink" title="2. 安装git"></a><font color="#CDAA7D">2. 安装git</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install git</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512702341648.png" alt=""><br><img src="http://p09u6sy9g.bkt.clouddn.com/1512702385850.png" alt=""></p>
<h4 id="3-安装hexo"><a href="#3-安装hexo" class="headerlink" title="3. 安装hexo"></a><font color="#CDAA7D">3. 安装hexo</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512702417480.png" alt=""></p>
<h4 id="4-创建工作文件夹"><a href="#4-创建工作文件夹" class="headerlink" title="4. 创建工作文件夹"></a><font color="#CDAA7D">4. 创建工作文件夹</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo init myblog</span><br><span class="line">cd /myblog; npm install</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512702453585.png" alt=""><br><img src="http://p09u6sy9g.bkt.clouddn.com/1512702547734.png" alt=""></p>
<h4 id="5-启动服务"><a href="#5-启动服务" class="headerlink" title="5. 启动服务"></a><font color="#CDAA7D">5. 启动服务</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s (完整命令hexo server，可简写)</span><br></pre></td></tr></table></figure>
<p>访问4000端口即可看到已经提供服务</p>
<h3 id="二-使用"><a href="#二-使用" class="headerlink" title="二 使用 "></a><font color="#CDAA7D">二 使用 </font></h3><h4 id="1-推一篇文章"><a href="#1-推一篇文章" class="headerlink" title="1.推一篇文章"></a><font color="#DDA0DD">1.推一篇文章</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new &quot;My first post with hexo&quot;</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512702662761.png" alt=""></p>
<p>该命令会在存放博客内容的文件夹（/myblog/source/_posts）内生成一个My first post with hexo.md文件,写入下文并使用hexo g(hexo generate)命令使hexo根据.md文件生成网页静态文件，hexo s 开启测试服务，访问4000端口即可看到新增的名为”My first post with hexo”的博客文章</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: My Fist Post with hexo</span><br><span class="line">date: 2016-09-25 20:03:25</span><br><span class="line">tags:</span><br><span class="line">---</span><br><span class="line">This my first post using [Hexo](https://hexo.io/)! </span><br><span class="line"></span><br><span class="line">## First title</span><br><span class="line"></span><br><span class="line">### a first subtitile </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    $ hexo new &quot;My New Post&quot;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">More info: [Writing](https://hexo.io/docs/writing.html)</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512702911276.png" alt=""></p>
<h4 id="2-将博客托管在github上"><a href="#2-将博客托管在github上" class="headerlink" title="2.将博客托管在github上"></a><font color="#DDA0DD">2.将博客托管在github上</font></h4><p>github创建的仓库可以提供一个链接，将静态页面文件以网页的形式展示出来。在git里面创建该特殊的仓库，然后通过修改hexo的配置文件将托管形式改成git，使用hexo d(hexo deployment)将本地生成博客文件推送到仓库，便可以通过github提供的服务访问博客，大概可以分为以下三步</p>
<h5 id="添加密钥"><a href="#添加密钥" class="headerlink" title="* 添加密钥"></a><font color="#DDA0DD">* 添加密钥</font></h5><p>在服务器生成密钥，添加到github里，使服务器和github可以进行文件的读写,具体操作步骤可以参考我的另一篇博客<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="external"><font color="#AAAAAA">Build your own blog with hexo</font></a>内容中相关部分</p>
<h5 id="安装可以实现将hexo文件部署到git的组建"><a href="#安装可以实现将hexo文件部署到git的组建" class="headerlink" title="* 安装可以实现将hexo文件部署到git的组建"></a><font color="#DDA0DD">* 安装可以实现将hexo文件部署到git的组建</font></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512713232758.png" alt=""></p>
<h5 id="修改配置文件并将内容推送到git"><a href="#修改配置文件并将内容推送到git" class="headerlink" title="* 修改配置文件并将内容推送到git"></a><font color="#DDA0DD">* 修改配置文件并将内容推送到git</font></h5><blockquote>
<p>修改配置文件</p>
</blockquote>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512716088946.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将博文推送到github上</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>
<p><img src="http://p09u6sy9g.bkt.clouddn.com/1512716177202.png" alt=""></p>
<p>至此，在本地部署一个博客网站，托管到gitbhub上，可以通过链接 <a href="https://uxtuo.github.io" target="_blank" rel="external">https://uxtuo.github.io</a> 访问，get！</p>
<h4 id="3-设置域名并用nginx代理"><a href="#3-设置域名并用nginx代理" class="headerlink" title="3.设置域名并用nginx代理 "></a><font color="#DDA0DD">3.设置域名并用nginx代理 </font></h4><p>将博客托管在github上和通过域名直接访问服务器的博客不冲突。<br><br>hexo作为生成静态文件的工具，编辑内容并生成博客文件,推送并访问位于git上的文件，亦或者通过ip或者域名访问服务器上的文件没有区别，这里申请一个域名对vps的ip进行解析，使游客可以通过域名直接访问服务器上的博客，并用nginx做代理处理对服务器的请求。</p>
<h5 id="申请域名并设置解析地址"><a href="#申请域名并设置解析地址" class="headerlink" title="* 申请域名并设置解析地址"></a><font color="#DDA0DD">* 申请域名并设置解析地址</font></h5><blockquote>
<p>在<a href="http://www.freenom.com/zh/index.html?lang=zh" target="_blank" rel="external"><font color="#AAAAAA">freenom</font></a>申请免费域名，设置域名解析为vps地址</p>
</blockquote>
<h5 id="设置nginx做代理以应付可能的高并发访问"><a href="#设置nginx做代理以应付可能的高并发访问" class="headerlink" title="* 设置nginx做代理以应付可能的高并发访问"></a><font color="#DDA0DD">* 设置nginx做代理以应付可能的高并发访问</font></h5><p>安装nginx（下载压缩包后解压到/usr/local/目录即可使用），修改配置文件，使nginx代理对该服务器80端口的所有访问，设置nginx解析位于/myblog/public目录hexo生成的静态网页文件</p>
<p>这样就可以实现通过域名访问部署在VPS上的博客，get！</p>
<blockquote>
<p>本博客就是通过上文方法搭建，所有操作均通过实验，有兴趣的筒子们可以跟着做，绝对轻松愉快可操作，有问题可以发邮件给我（yung241088@126.com）,我一定会看但不一定会回/滑稽</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> env </category>
            
        </categories>
        
        
        <tags>
            
            <tag> blog </tag>
            
            <tag> env </tag>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Build your own blog with hexo]]></title>
      <url>/2017/11/10/what-is-hexo/</url>
      <content type="html"><![CDATA[<h2 id="What-is-Hexo"><a href="#What-is-Hexo" class="headerlink" title="What is Hexo?"></a><font color="#5CACEE">What is Hexo?</font></h2><blockquote>
<p>Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other languages) and Hexo generates static files with a beautiful theme in seconds.<br>Installing Hexo is quite easy. However, you do need to have Nodejs &amp; Git installed first.<br>In order to install Nodejs you can see Install &amp; run your first application Nodejs.<br>In order to install Git you can see <a href="https://git-scm.com/" target="_blank" rel="external">https://git-scm.com/</a> .</p>
</blockquote>
<a id="more"></a>
<h2 id="Install-Hexo"><a href="#Install-Hexo" class="headerlink" title="Install Hexo"></a><font color="#5CACEE">Install Hexo</font></h2><p>  Once all the requirements are installed,you can install Hexo.<br> <br> $ npm install -g hexo-cli</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOiqe.png" alt="vOiqe.png"></p>
</blockquote>
<h2 id="Create-a-blog"><a href="#Create-a-blog" class="headerlink" title="Create a blog"></a><font color="#5CACEE">Create a blog</font></h2><p>  Now that hexo is installed run the following commands to initialise Hexo project<br> <br>$ hexo init myblog <br> $ cd myblog  <br>$ npm install</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOIiN.png" alt="vOIiN.png"></p>
</blockquote>
<p>You can modify site settings in <font color="brow" size="2">_config.yml</font>. for the sake of simplicity we�re only modify the Title and author name .</p>
<h2 id="Run-the-Blog"><a href="#Run-the-Blog" class="headerlink" title="Run the Blog"></a><font color="#5CACEE">Run the Blog</font></h2><p>  Run the server:<br><br>    $ hexo server </p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOfzK.png" alt="vOfzK.png"><br>  launch your browser and navigate to <a href="http://localhost:4000" target="_blank" rel="external">http://localhost:4000</a>.<br><img src="https://t1.picb.cc/uploads/2017/11/10/vOZcj.png" alt="vOZcj.png"><br>Voila your first blog is working!</p>
</blockquote>
<h2 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a><font color="#5CACEE">Create a new post</font></h2><p>  Create a new post is very simlpe all what you have to do is :<br>  <br>   $ hexo new “My Fist Post with hexo”</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOVrX.png" alt="vOVrX.png"><br>Update the file using Markdown language:</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: My Fist Post with hexo</span><br><span class="line">date: 2016-09-25 20:03:25</span><br><span class="line">tags:</span><br><span class="line">---</span><br><span class="line">This my first post using [<span class="string">Hexo</span>](<span class="link">https://hexo.io/</span>)! </span><br><span class="line"></span><br><span class="line"><span class="section">## First title</span></span><br><span class="line"></span><br><span class="line"><span class="section">### a first subtitile </span></span><br><span class="line"></span><br><span class="line"><span class="code">    /usr/bin/bash</span></span><br><span class="line"><span class="code">    $ hexo new "My New Post"</span></span><br><span class="line"><span class="code">    </span></span><br><span class="line"></span><br><span class="line"><span class="section">## Second title</span></span><br><span class="line"></span><br><span class="line">More info: [<span class="string">Writing</span>](<span class="link">https://hexo.io/docs/writing.html</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOgSG.png" alt="vOgSG.png"><br>  Run the server again:<br> <br>   $ hexo server<br><img src="https://t1.picb.cc/uploads/2017/11/10/vOnxs.png" alt="vOnxs.png"></p>
</blockquote>
<h2 id="Deployment-on-Github"><a href="#Deployment-on-Github" class="headerlink" title="Deployment on Github"></a><font color="#5CACEE">Deployment on Github</font></h2><p>  Now what about Deployment, it�s exactly what we are going to do, first Create new Github repository :</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOwQc.png" alt="vOwQc.png"><br>  Click settings<br><img src="https://t1.picb.cc/uploads/2017/11/10/vOlt7.png" alt="vOlt7.png"><br><img src="https://t1.picb.cc/uploads/2017/11/10/vOCST.png" alt="vOCST.png"><br>  Then install hexo-deployer-git:<br> <br>  $ npm install hexo-deployer-git –save<br><img src="https://t1.picb.cc/uploads/2017/11/10/vOyx8.png" alt="vOyx8.png"></p>
</blockquote>
<p>  Click clone or download button:</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOu56.png" alt="vOu56.png"></p>
</blockquote>
<p>  Update _config.yaml file :</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOtyy.png" alt="vOtyy.png"></p>
</blockquote>
<p>  It�s time for deployement :<br>  <br> $ hexo deploy</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOJtg.png" alt="vOJtg.png"></p>
</blockquote>
<p>  To preview launch your browser.</p>
<blockquote>
<p><img src="https://t1.picb.cc/uploads/2017/11/10/vOmyM.png" alt="vOmyM.png"></p>
</blockquote>
<p>You can get see the blog on <a href="https://malektrainer.github.io/" target="_blank" rel="external">https://malektrainer.github.io/</a>.<br><br>You can find source code on <a href="https://github.com/malektrainer/myblog" target="_blank" rel="external">https://github.com/malektrainer/myblog</a>.</p>
]]></content>
      
        <categories>
            
            <category> blog </category>
            
        </categories>
        
        
        <tags>
            
            <tag> blog </tag>
            
            <tag> server </tag>
            
            <tag> environment </tag>
            
            <tag> mark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[构建基于Busybox的Nginx服务容器]]></title>
      <url>/2016/04/22/%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8EBusybox%E7%9A%84Nginx%E6%9C%8D%E5%8A%A1%E5%AE%B9%E5%99%A8/</url>
      <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a><font color="#5CACEE">简介</font></h2><blockquote>
<p>用docker容器进行打包服务非常方便 不需要考虑依赖的问题 只要把容器复制到其他有docker daemon的服务器就可以直接启动 并能很方便的利用Cgroup, Namespace技术实现资源控制和资源隔离<br>这篇文档以Nginx为例 其他的像redis mysql php等服务也是可以使用这个方法进行打包为最精简的 只包含必须依赖的服务容器</p>
</blockquote>
<a id="more"></a>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a><font color="#5CACEE">环境</font></h2><blockquote>
<p>系统是ubuntu server 15.10版 用ubuntu系统作为docker服务的载体 如果非ubuntu15.10发行版 尽量保证内核版本在3.18以上 Nginx是在CentOS 6.7的容器中编译的 之后在ubuntu上完成打包<br>在容器中编译Nginx只是我的个人习惯 不喜欢将主机环境乱安装一些不必要的包 保持清洁就好 编译什么的就交给容器去做吧</p>
</blockquote>
<h3 id="主机环境"><a href="#主机环境" class="headerlink" title="主机环境"></a><font color="#CDAA7D">主机环境</font></h3><table>
<thead>
<tr>
<th>身份</th>
<th style="text-align:center">系统</th>
<th style="text-align:right">IP</th>
</tr>
</thead>
<tbody>
<tr>
<td>Docker服务</td>
<td style="text-align:center">ubuntu 15.10</td>
<td style="text-align:right">172.17.0.1</td>
</tr>
<tr>
<td>Docker容器</td>
<td style="text-align:center">CentOS 6.7</td>
<td style="text-align:right">172.17.0.3</td>
</tr>
</tbody>
</table>
<h3 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a><font color="#CDAA7D">软件环境</font></h3><table>
<thead>
<tr>
<th>软件名称</th>
<th style="text-align:center">版本号</th>
<th style="text-align:right">下载地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Nginx</td>
<td style="text-align:center">1.9.15</td>
<td style="text-align:right"><a href="http://nginx.org/download/nginx-1.9.15.tar.gz" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>Docker</td>
<td style="text-align:center">1.9.1</td>
<td style="text-align:right"><a href="http://mirrors.aliyun.com/docker-engine/apt/pool/main/d/docker-engine/docker-engine_1.9.1-0~wily_amd64.deb" target="_blank" rel="external"><font color="#AAAAAA">点击下载</font></a></td>
</tr>
<tr>
<td>kernel</td>
<td style="text-align:center">4.2.0</td>
<td style="text-align:right"><font color="#AAAAAA">系统自带</font></td>
</tr>
</tbody>
</table>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a><font color="#5CACEE">步骤</font></h2><p>以下是打包Nginx服务容器的基本思路</p>
<ul>
<li>选用Busybox环境作为基础</li>
<li>在CentOS 容器中编译Nginx</li>
<li>将Nginx的运行依赖库和Nginx程序复制到主机环境</li>
<li>部署到Busybox构建的rootfs中</li>
<li>导入Docker 查看是否正常运行</li>
</ul>
<h3 id="构建Busybox最小容器"><a href="#构建Busybox最小容器" class="headerlink" title="构建Busybox最小容器"></a><font color="#CDAA7D">构建Busybox最小容器</font></h3><blockquote>
<p>Busybox构建文档：<a href="/2016/04/21/docker/Busybox构建最小容器"><font color="#AAAAAA">点击打开文档内容</font></a><br>构建完毕之后 busybox-1.24.2/_install 就是我们需要当作容器基础的rootfs了 将它复制到随便一个目录 留用</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -rf busybox-1.24.2/_install/ rootfs</span><br></pre></td></tr></table></figure>
<h3 id="编译安装Nginx"><a href="#编译安装Nginx" class="headerlink" title="编译安装Nginx"></a><font color="#CDAA7D">编译安装Nginx</font></h3><blockquote>
<p>Nginx的编译文档：<a href="/2016/03/31/nginx/nginx编译安装"><font color="#AAAAAA">点击打开文档内容</font></a><br>只需要做到文档中make -j4 也就是编译完成就可以了 之后的安装步骤就不按照文档的走了</p>
</blockquote>
<h4 id="安装nginx到非默认根"><a href="#安装nginx到非默认根" class="headerlink" title="安装nginx到非默认根"></a><font color="#DDA0DD">安装nginx到非默认根</font></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make DESTDIR=/nginx install</span><br></pre></td></tr></table></figure>
<p>通过DESTDIR更改安装Nginx的根位置 以/nginx目录作为nginx安装的根</p>
<pre><code>[root@localhost nginx-1.9.15]# ls /nginx/
usr  var
[root@localhost nginx-1.9.15]# tree /nginx/
/nginx/
├── usr
│   └── local
│       └── nginx
│           ├── conf
│           │   ├── fastcgi.conf
│           │   ├── fastcgi.conf.default
│           │   ├── fastcgi_params
│           │   ├── fastcgi_params.default
│           │   ├── koi-utf
│           │   ├── koi-win
│           │   ├── mime.types
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /nginx/</span><br><span class="line">mkdir lib lib64                     <span class="comment"># 创建两个依赖库文件夹</span></span><br><span class="line">strip usr/<span class="built_in">local</span>/nginx/sbin/nginx    <span class="comment"># 裁剪nginx二进制的编译跟踪信息 缩减nginx体积</span></span><br></pre></td></tr></table></figure>
<h4 id="复制Nginx运行依赖库"><a href="#复制Nginx运行依赖库" class="headerlink" title="复制Nginx运行依赖库"></a><font color="#DDA0DD">复制Nginx运行依赖库</font></h4><blockquote>
<p>接下来查看nginx程序的所有依赖</p>
</blockquote>
<pre><code>[root@localhost nginx]# ldd usr/local/nginx/sbin/nginx 
    linux-vdso.so.1 =&gt;  (0x00007fff3caa3000)
    libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f9bc2ff8000)
    libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f9bc2ddb000)
    libcrypt.so.1 =&gt; /lib64/libcrypt.so.1 (0x00007f9bc2ba3000)
    libz.so.1 =&gt; /lib64/libz.so.1 (0x00007f9bc298d000)
    libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f9bc25f9000)
    /lib64/ld-linux-x86-64.so.2 (0x0000561c3968f000)
    libfreebl3.so =&gt; /lib64/libfreebl3.so (0x00007f9bc23f5000)
</code></pre><p>将依赖复制到刚才创建的lib或者lib64目录中 如果这个依赖库在系统的lib目录下 那么就复制到lib目录中<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cp /lib64/libdl.so.2 lib64/</span><br><span class="line">cp /lib64/libpthread.so.0 lib64/</span><br><span class="line">cp /lib64/libcrypt.so.1 lib64/</span><br><span class="line">cp /lib64/libz.so.1 lib64/</span><br><span class="line">cp /lib64/libc.so.6 lib64/</span><br><span class="line">cp /lib64/ld-linux-x86-64.so.2 lib64/</span><br><span class="line">cp /lib64/libfreebl3.so lib64/</span><br></pre></td></tr></table></figure></p>
<p> 由于Nginx运行需要使用普通用户 所以需要读取passwd文件 读取解析passwd文件需要用到libnss_files.so.2这个库 所以也需要复制这个库到lib64中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /lib64/libnss_files.so.2 lib64/</span><br></pre></td></tr></table></figure>
<p>如果在ubuntu上编译的话libnss_files.so.2位置在/lib/x86_64-linux-gnu/libnss_files.so.2<br>复制完成后lib64目录的内容应该如下所示：</p>
<pre><code>[root@localhost nginx]# ls lib64/
ld-linux-x86-64.so.2  libc.so.6   libfreebl3.so      libpthread.so.0
libcrypt.so.1         libdl.so.2  libnss_files.so.2  libz.so.1
</code></pre><h3 id="打包Nginx服务容器"><a href="#打包Nginx服务容器" class="headerlink" title="打包Nginx服务容器"></a><font color="#CDAA7D">打包Nginx服务容器</font></h3><blockquote>
<p>Nginx以及Nginx的运行依赖都已经放到/nginx目录中了 将这个目录移动到和刚才的rootfs同一目录下 然后再创建两个目录 留用</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir build target</span><br></pre></td></tr></table></figure>
<h4 id="认识overlayFS"><a href="#认识overlayFS" class="headerlink" title="认识overlayFS"></a><font color="#DDA0DD">认识overlayFS</font></h4><blockquote>
<p>overlay是一种联合挂载的文件系统 可以将几个不同的目录挂载到一个目录中 然后将所有的文件展示出来 而且在挂载的目录中对文件的操作并不会影响到其他目录中实际的文件<br>同时 在新版本的docker中 overlay便是docker容器默认使用的存储驱动 但是overlay在内核大于3.18的版本中才被支持 所以尽量用使用较新内核版本的发行版来玩Docker<br>因为overlay的这些特性 用来辅助制作Nginx服务容器岂不是很方便 因为在挂载的目录中的操作并不会影响基层目录的文件 这样就算误删了文件 也是可以恢复的</p>
</blockquote>
<p>现在看起来 应该是这个效果</p>
<pre><code>root@ubuntu:~# ls -lh
total 16K
drwxr-xr-x  9 root root 4.0K Apr 22 12:50 build     # overlay的工作目录
drwxr-xr-x  6 root root 4.0K Apr 22 15:34 nginx     # 刚才安装的Nginx目录
drwxr-xr-x 18 root root 4.0K Apr 22 11:52 rootfs    # busybox的目录
drwxr-xr-x  1 root root 4.0K Apr 22 12:50 target    # 这个就是联合挂载到的目标目录
</code></pre><p>检查overlay驱动是否已经加载 否则加载overlay驱动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lsmod |grep overlay</span><br><span class="line">modprobe overlay</span><br></pre></td></tr></table></figure></p>
<p>如下所示 那么就可以使用overlay文件系统了 </p>
<pre><code>root@ubuntu:~# lsmod |grep overlay
overlay                49152  1
root@ubuntu:~# cat /proc/filesystems |grep overlay
nodev    overlayfs
nodev    overlay
</code></pre><p>用rootfs和nginx做基层 其中rootfs是第一层 如果还有其他目录 依次用冒号隔开 build做为overlay工作目录  /tmp是overlay必须的一个空目录 将lowerdir中的目录都挂载到target目录上<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t overlay overlay -o lowerdir=rootfs:nginx,upperdir=build,workdir=/tmp target/</span><br></pre></td></tr></table></figure></p>
<p>接下来可以看到target目录中 rootfs和nginx目录中的内容同时出现在target目录中</p>
<pre><code>root@ubuntu:~# ls target/
bin  etc   lib    linuxrc  mnt   root  sbin  tmp  var
dev  home  lib64  media    proc  run   sys   usr
root@ubuntu:~# ls target/bin/busybox 
target/bin/busybox
root@ubuntu:~# ls target/usr/local/nginx/sbin/nginx 
target/usr/local/nginx/sbin/nginx
</code></pre><p>如果系统刚好不支持overlay文件系统的话 思想原理是相同的 直接将rootfs和nginx目录中的文件都复制到target中吧</p>
<h4 id="Chroot进行根切换"><a href="#Chroot进行根切换" class="headerlink" title="Chroot进行根切换"></a><font color="#DDA0DD">Chroot进行根切换</font></h4><blockquote>
<p>接下来就是配置Nginx的运行环境了 这样才能保证Nginx打包为容器后能正常的运行<br>通过chroot工具切换当前根到target目录中 这也算文件系统隔离一种的方式</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chroot target sh</span><br></pre></td></tr></table></figure>
<p>可以看到 进入到了一个不同的shell中 ls / 竟然发现了linuxrc文件 现在已经将根切换到target目录中了</p>
<pre><code>/ # ls /
bin      etc      lib      linuxrc  mnt      root     sbin     tmp      var
dev      home     lib64    media    proc     run      sys      usr
</code></pre><h4 id="根据执行Nginx的报错进行配置"><a href="#根据执行Nginx的报错进行配置" class="headerlink" title="根据执行Nginx的报错进行配置"></a><font color="#DDA0DD">根据执行Nginx的报错进行配置</font></h4><p>接下来的操作在这个根中进行 配置Nginx的运行环境 这些操作都是通过不断的执行nginx程序 查看nginx的报错总结的</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">adduser nginx                       <span class="comment"># 添加nginx用户 </span></span><br><span class="line">mkdir -p /var/tmp/nginx/client/     <span class="comment"># 创建nginx运行需要的目录</span></span><br><span class="line">mkdir -p /var/www/html              <span class="comment"># 以后将使用这个路径作为Nginx网页根目录</span></span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/nginx/sbin/nginx /usr/sbin/            <span class="comment"># 添加nginx软链接到环境变量中</span></span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/nginx/conf/nginx.conf /etc/nginx.conf  <span class="comment"># 添加配置文件软连接到/etc目录</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;h1&gt;hello nginx&lt;/h1&gt;'</span> &gt; /var/www/html/index.html  <span class="comment"># 创建一个索引文件</span></span><br></pre></td></tr></table></figure>
<p>再次运行nginx程序 这时候遇到了ginx: [emerg] open(“/dev/null”) failed的错误 原因是打不开这个设备文件 这个只能通过启动为一个Docker容器来解决了</p>
<pre><code>/ # /usr/local/nginx/sbin/nginx 
nginx: [emerg] open(&quot;/dev/null&quot;) failed (2: No such file or directory)
</code></pre><h4 id="修改Nginx配置文件"><a href="#修改Nginx配置文件" class="headerlink" title="修改Nginx配置文件"></a><font color="#DDA0DD">修改Nginx配置文件</font></h4><p>剩下的就是修改nginx的配置文件了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/nginx.conf</span><br></pre></td></tr></table></figure>
<pre><code>第一行添加 daemon off; 让nginx前台运行 这个必须添加
http{}中添加 autoindex on; 运行目录索引 可以根据实际情况添加
http{
  server{
    location / {
        root   /var/www/html;           # root改为/var/www/html 可以根据实际情况更改
        index  index.html index.htm;
    }
  }
}
</code></pre><h4 id="将目录打包为Docker容器"><a href="#将目录打包为Docker容器" class="headerlink" title="将目录打包为Docker容器"></a><font color="#DDA0DD">将目录打包为Docker容器</font></h4><p>输入exit或者键入 Ctrl+d 就可以退出chroot 回到正常的根中了 接下来 将数据打包为Docker容器 可以看到 大小仅仅8M<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> target/</span><br><span class="line">tar -cf /dev/stdout *|docker import - nginx:1.9.15</span><br></pre></td></tr></table></figure></p>
<pre><code>root@ubuntu:~/target# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
nginx               1.9.15              99089cedcc48        3 seconds ago       8.071 MB
</code></pre><h4 id="启动容器-检查是否成功"><a href="#启动容器-检查是否成功" class="headerlink" title="启动容器 检查是否成功"></a><font color="#DDA0DD">启动容器 检查是否成功</font></h4><p>然后后台启动这个容器 并且查看容器IP 通过curl命令检查nginx是否正常运行 可以看到 成功返回 hello nginx<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name nginx nginx:1.9.15 nginx</span><br><span class="line">docker inspect --format <span class="string">'&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;'</span> nginx</span><br></pre></td></tr></table></figure></p>
<pre><code>root@ubuntu:~/target# docker run -d --name nginx nginx:1.9.15 nginx
0db0d45152948339fb0c9a23e8dfba6798c650e24075d725ba2d3021eb3b801b
root@ubuntu:~/target# docker inspect --format &apos;{{.NetworkSettings.IPAddress}}&apos; nginx
172.17.0.8
root@ubuntu:~/target# curl 172.17.0.8
&lt;h1&gt;hello nginx&lt;/h1&gt;
root@ubuntu:~/target#
</code></pre><p>这样 一个非常小 但是可以提供完整功能的Nginx服务容器就打包完成了 </p>
<h4 id="overlayFS文件误删的恢复"><a href="#overlayFS文件误删的恢复" class="headerlink" title="overlayFS文件误删的恢复"></a><font color="#DDA0DD">overlayFS文件误删的恢复</font></h4><p>如果在制作这个容器的过程中 不幸误删了target目录中的文件 还记的build这个文件吗<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf linuxrc</span><br></pre></td></tr></table></figure></p>
<pre><code>root@ubuntu:~/target# ls -l ../build/linuxrc 
c--------- 1 root root 0, 0 Apr 22 17:28 ../build/linuxrc
</code></pre><p>可以看到 build目录中出现了一个主次设备号都为0的字符设备 只要删除了这个字符设备 文件就恢复了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ../build/linuxrc</span><br></pre></td></tr></table></figure></p>
<pre><code>root@ubuntu:~/target# ls
bin  etc   lib    linuxrc  mnt   root  sbin  tmp  var
dev  home  lib64  media    proc  run   sys   usr
</code></pre><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a><font color="#5CACEE">附录</font></h2><h3 id="将Nginx容器镜像保存为文件"><a href="#将Nginx容器镜像保存为文件" class="headerlink" title="将Nginx容器镜像保存为文件"></a><font color="#CDAA7D">将Nginx容器镜像保存为文件</font></h3><blockquote>
<p>如果想把这个容器共享给其他人使用 除了使用push到仓库中 还可以直接通过文件的方式共享</p>
</blockquote>
<h4 id="配置一个默认启动命令"><a href="#配置一个默认启动命令" class="headerlink" title="配置一个默认启动命令"></a><font color="#DDA0DD">配置一个默认启动命令</font></h4><blockquote>
<p>导入这个Nginx服务容器之后 每次启动都需要手动输入nginx命令 这样显的比较麻烦 可以通过Dockerfile的方式给这个容器配置一个默认的启动命令</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim Dockerfile</span><br></pre></td></tr></table></figure>
<pre><code>键入以下内容：
root@ubuntu:~# cat Dockerfile 
FROM nginx:1.9.15
CMD nginx

nginx就是启动的命令 如果命令还带有参数 可以直接写出 例如 CMD nginx -s reload
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t nginx .         <span class="comment"># 给新镜像配置一个标签 记得不要忘记了最后的 .</span></span><br></pre></td></tr></table></figure>
<pre><code>root@ubuntu:~# docker build -t nginx .
Sending build context to Docker daemon 25.09 MB
Step 1 : FROM nginx:1.9.15
 ---&gt; 99089cedcc48
Step 2 : CMD nginx
 ---&gt; Running in 12b1a81d553c
 ---&gt; 114ba21e8f1c
Removing intermediate container 12b1a81d553c
Successfully built 114ba21e8f1c
root@ubuntu:~# docker run -d nginx:latest
0f3f39dd3aea5a16b10a470ffecca716b31d0deab5420b07ee86bd1180bc2256
</code></pre><p>可以看到 启动这个新容器已经不需要输入nginx命令了 其实还有一个方法可以更改默认启动命令 通过直接修改镜像的配置文件<br>可以看到 nginx:1.9.15镜像的ID是99089cedcc48 这只是完整ID的一部分 配置信息保存在/var/lib/docker/graph中</p>
<pre><code>root@ubuntu:~# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
nginx               1.9.15              99089cedcc48        48 minutes ago      8.071 MB
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/lib/docker/graph</span><br><span class="line"><span class="built_in">cd</span> 99089cedcc48*</span><br><span class="line">vim json</span><br></pre></td></tr></table></figure>
<p>这时就打开了这个镜像的配置文件 Cmd字段就是默认命令 还可以顺便改下comment信息</p>
<pre><code>&quot;comment&quot;:&quot;nginx 1.9.15&quot;,       # comment字段改为你想表达的信息
&quot;Cmd&quot;:[&quot;yunfwe&quot;],               # Cmd字段有两个 第一个是作者信息
&quot;Cmd&quot;:[&quot;nginx&quot;],                # 第二个才是启动命令

如果运行命令有其他参数的话 用逗号隔开 例如 &quot;Cmd&quot;:[&quot;nginx&quot;,&quot;-s&quot;,&quot;reload&quot;],
这样就相当于 nginx -s reload 了
</code></pre><p>接下来使用docker history nginx:1.9.11 查看信息</p>
<pre><code>可以看到 CREATED BY 还有 COMMENT 是自己写的信息了
root@ubuntu:~# docker history 99089cedcc48
IMAGE               CREATED             CREATED BY          SIZE                COMMENT
99089cedcc48        58 minutes ago      yunfwe              8.071 MB           nginx 1.9.15

顺便可以看到运行命令也已经是nginx了
root@ubuntu:~# docker inspect --format {{.Config.Cmd}} nginx:1.9.15
{[nginx]}
</code></pre><p>这两种修改默认启动命令方法的一个重要区别是 第二种在原本的镜像上修改 是不会产生新的层的 而用Dockerfile修改 相当于新建了一个层 这个层提供了默认启动命令 不信可以使用docker history验证一下</p>
<h4 id="保存为文件"><a href="#保存为文件" class="headerlink" title="保存为文件"></a><font color="#DDA0DD">保存为文件</font></h4><blockquote>
<p>默认docker导出的是个tar归档 这里直接将归档压缩为gz包 文件命名规则是<br>REPOSITORY_TAG-Type.tar.gz<br>其中的Type是标识这个文件是由镜像保存的还是已经生成的容器导出的</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker save nginx:1.9.15 |gzip &gt; nginx_1.9.15-image.tar.gz</span><br></pre></td></tr></table></figure>
<p>要恢复的话也很简单 docker支持直接从gz压缩包中恢复<br>导入新的镜像 这个镜像的标签可能会丢失 但是id号还在 给这个id好重新打个标签</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker load &lt; nginx_1.9.15-image.tar.gz</span><br><span class="line">docker tag 99089cedcc48 nginx:1.9.15</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> docker </tag>
            
            <tag> nginx </tag>
            
            <tag> busybox </tag>
            
            <tag> overlay </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
